{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Econometrics - Assignment 1 Tutorial\n",
    "## Author: Jaepil Lee\n",
    "## October 21, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Preliminary: Beta Distribution and Conjugate Prior](#preliminary)<a name=\"preliminary_menu\"></a>\n",
    "### [Static Problem](#static)<a name=\"static_menu\"></a>\n",
    "### [Dynamic Problem: 2 periods](#dynamic2periods)<a name=\"dynamic2_menu\"></a>\n",
    "### [Dynamic Problem: Infinite horizon](#dynamic_infty)<a name=\"dynamic_infty_menu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this assignment is summarized as follows:\n",
    "- Time horizon: $t=1,\\ldots,T$ where $T\\leq\\infty$.\n",
    "- Choice variable: $d_t=\\begin{cases}\n",
    "    0 & \\text{ if `do the outside option'} \\\\ \n",
    "    1 & \\text{ if `invent'} \n",
    "    \\end{cases}$\n",
    "- Outcome of invention: $x_t=\\begin{cases}\n",
    "    0 & \\text{ if `failure'} \\\\ \n",
    "    1 & \\text{ if `success'} \n",
    "    \\end{cases}$\n",
    "- Payoff of success is 1, failure is 0.\n",
    "- The payoff of choosing the outside option: $w$\n",
    "- Ability parameter: $\\xi\\in(0,1)$\n",
    "- The agent knows that the ability $\\xi\\sim\\text{Beta}(\\gamma,\\delta)$.\n",
    "- Lifetime utility: $\\sum_{t=1}^{T} \\beta^{t-1} [d_t\\mathbf{1} \\{x_t=1\\} + (1-d_t)w]$\n",
    "- *Implied* assumption: the agent is risk neutral (i.e., expected payoff maximizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Preliminary: Beta Distribution and Conjugate Prior](#preliminary_menu)<a name=\"preliminary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $\\xi\\sim\\text{Beta}(\\gamma, \\delta)$. Then we have the following properties:\n",
    "- pdf: $g(\\xi;\\gamma,\\delta) = \\frac{\\xi^{\\gamma-1} (1-\\xi)^{\\delta-1}}{\\text{B}(\\gamma,\\delta)}$ where $\\text{B}(\\gamma,\\delta)=\\int_{0}^{1} u^{\\gamma-1}(1-u)^{\\delta-1}du$\n",
    "- Mean: $\\mathbb{E}(\\xi;\\gamma,\\delta) = \\frac{\\gamma}{\\gamma+\\delta}$\n",
    "- Intuition: \"$\\gamma$ successes, $\\delta$ failures\"\n",
    "- For more information: [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n",
    "\n",
    "If the agent invents, she will get the result of inventing, either success or failure. Based on the result, she will update her belief about her ability by updating her parameters $(\\gamma, \\delta)$ via [Bayes' rule](https://en.wikipedia.org/wiki/Bayesian_inference).\n",
    "\n",
    "Statisticians found many cases where the prior distribution and posterior distribution are in the same distribution family after Bayesian update. The prior distribution in this case is called a [conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior) for the likelihood function. In Miller (1984), the conjugate prior is a normal distribution and the likelihood is also a normal distribution. In this assignment, the conjugate prior is a beta distribution and the likelihood is a Bernoulli distribution.\n",
    "\n",
    "The prior distribution of $\\xi$ given parameters $(\\gamma, \\delta)$ is\n",
    "$$\n",
    "g(\\xi;\\gamma,\\delta)=\\frac{\\xi^{\\gamma-1} (1-\\xi)^{\\delta-1}}{\\text{B}(\\gamma,\\delta)} \\text{ where }  \\text{B}(\\gamma,\\delta)=\\int_{0}^{1} u^{\\gamma-1}(1-u)^{\\delta-1}du\n",
    "$$\n",
    "and the likelihood of the outcome $x\\in\\{0,1\\}$ given $\\xi$ is\n",
    "$$\n",
    "    f(x\\,|\\,\\xi)= \\xi^{x} (1-\\xi)^{1-x}.\n",
    "$$\n",
    "The agent's posterior belief is derived by using Bayes' rule:\n",
    "$$\n",
    "\\begin{split}\n",
    "    f(\\xi|x)& =\\frac{f(x|\\xi)}{f(x)}g(\\xi)=\\frac{f(x|\\xi)}{\\int_{0}^{1}f(x|\\xi)g(\\xi)d\\xi}g(\\xi)= \\frac{\\xi^{x}(1-\\xi)^{1-x}}{\\int_{0}^{1}\\xi^{x}(1-\\xi)^{1-x}\\frac{{\\xi}^{\\gamma-1}(1-\\xi)^{\\delta-1}}{\\text{B}(\\gamma,\\delta)}d\\xi}\\frac{\\xi^{\\gamma-1}(1-\\xi)^{\\delta-1}}{\\text{B}(\\gamma,\\delta)}\\\\\n",
    "    & = \\frac{\\xi^{\\gamma+x-1}(1-\\xi)^{\\delta+(1-x)-1}}{\\int_{0}^{1}\\xi^{\\gamma+x-1}(1-\\xi)^{\\delta+(1-x)-1}d\\xi}= \\frac{\\xi^{\\gamma+x-1}(1-\\xi)^{\\delta+(1-x)-1}}{\\text{B}(\\gamma+x,\\delta+(1-x))}\n",
    "\\end{split}\n",
    "$$\n",
    "Therefore, the agent's updated belief about her ability follows a beta distribution with parameters $(\\gamma+x,\\delta+(1-x))$.\n",
    "\n",
    "The updated expected payoff is then:\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{1}\\{x'=1\\}|\\gamma',\\delta'] = \\frac{\\gamma'}{\\gamma' + \\delta'} = \n",
    "    \\begin{cases}\n",
    "        \\frac{\\gamma}{\\gamma + (\\delta+1)} & \\text{ if } x=0\\\\\n",
    "        \\frac{\\gamma+1}{(\\gamma+1) + \\delta} & \\text{ if } x=1\n",
    "    \\end{cases}\n",
    "$$\n",
    "If the agent chooses not to invent, then there will be no update on her parameters (there is no information to update the parameters). Thus, the agent's belief about her ability in the next period will still be  $\\xi \\sim \\text{Beta}(\\gamma, \\delta)$. i.e., the agent solves the recursive problem in the next period with the same parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Static problem](#static_menu)<a name=\"static\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple setting. Let's suppose that we are solving a static model. In this case the lifetime utility is \n",
    "$$d_t\\mathbf{1} \\{x_t=1\\} + (1-d_t)w.$$\n",
    "\n",
    "If we knew the **exact value** of $\\xi$, then the decision rule is simple: we choose to invent if the expected payoff of invention is larger than the payoff of the outside option given $\\xi$:\n",
    "$$\n",
    "\\mathbb{E}_{x}\\big[1\\cdot\\mathbf{1}\\{x=1\\}+0\\cdot\\mathbf{1}\\{x=0\\}|\\xi]=1\\cdot\\mathbb{P}(x=1|\\xi) + 0\\cdot\\mathbb{P}(x=0|\\xi) = \\xi.\n",
    "$$\n",
    "In this case, the decision rule would be: \n",
    "$$d_t=\\begin{cases} 1 &\\text{ if } \\xi>w \\\\ \n",
    "0  &\\text{ otherwise } \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the agent only knows that her ability $\\xi$ is a random draw from a beta distribution $\\text{Beta}(\\gamma,\\delta)$, not its exact value. As a risk-neutral agent, the agent would compute her expected return on inventing and decide whether it is worth trying or not.\n",
    "$$\n",
    "\\mathbb{E}_{\\xi} \\Big[\\mathbb{E}_{x} \\big[ \\mathbf{1}\\{x=1\\} \\big| \\xi \\big] \\Big|\\gamma,\\delta\\Big] =\\mathbb{E}_{\\xi} \\big[1 \\cdot \\mathbb{P}(x=1|\\xi) + 0 \\cdot \\mathbb{P}(x=0|\\xi) \\big| \\gamma,\\delta \\big] =\\mathbb{E}_{\\xi} [1 \\cdot \\xi + 0 \\cdot (1-\\xi) | \\gamma,\\delta] = \\mathbb{E}_{\\xi}[{\\xi}|\\gamma,\\delta]=\\frac{\\gamma}{\\gamma+\\delta}.\n",
    "$$\n",
    "The decision rule is then:\n",
    "$$\n",
    "d_t=\\begin{cases} 1 &\\text{ if } \\frac{\\gamma}{\\gamma+\\delta}>w \\\\ \n",
    "0  &\\text{ otherwise } \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make simulated data of $N$ agents with this decision rule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 9:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 5:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 6:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 12:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 8:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 14:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 10:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 4:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 15:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 16:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 11:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 13:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 2:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 3:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 7:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "# Importing packages...\n",
    "using Pkg; Pkg.activate(\"./..\")\n",
    "using Distributions, Statistics, Random,\n",
    "    LinearAlgebra, Distances, SharedArrays, \n",
    "    Optim, ForwardDiff, NLSolversBase, \n",
    "    Plots, Printf, LaTeXStrings, PlotThemes;\n",
    "#=\n",
    "Distributed.jl is used for parallelization\n",
    "@everywhere is a macro to tell all the processors do the commands that follows\n",
    "@distributed is a macro to tell all the processors share the work on the loop\n",
    "SharedArrays{T} type is a type of Arrays that multiple processors can have access\n",
    "@sync is a macro to tell the processors do the loop in a synchronized manner\n",
    "=#\n",
    "using Distributed; addprocs(15); # Use addprocs(N-1) to use all N processors in your PC.\n",
    "@everywhere begin\n",
    "    using Pkg; Pkg.activate(\"./..\")\n",
    "    using Distributions, Statistics, Random,\n",
    "        LinearAlgebra, Distances, SharedArrays, \n",
    "        Optim, ForwardDiff, NLSolversBase, \n",
    "        Plots, Printf, LaTeXStrings, PlotThemes;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function d_static(γ,δ,w)\n",
    "    # Decision rule in a static case\n",
    "    if γ/(γ+δ)>w\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end;\n",
    "\n",
    "Random.seed!(42) # This sets the seed for RNG so that we get the same result.\n",
    "γ = 3.0; δ = 1.0; w = 10.5; N = 10_000;\n",
    "γData = Array{Float64}(zeros(N,1));\n",
    "δData = Array{Float64}(zeros(N,1));\n",
    "dData = Array{Float64}(zeros(N,1));\n",
    "xData = Array{Float64}(zeros(N,1));\n",
    "for i=1:N\n",
    "    γData[i,1] = γ\n",
    "    δData[i,1] = δ\n",
    "    dData[i,1] = d_static(γ,δ,w)\n",
    "end\n",
    "\n",
    "# We draw a random number ξ from Beta(γ,δ) N-times.\n",
    "ξ = rand(Beta(γ,δ),N)\n",
    "\n",
    "# We flip a coin for each agent *i* whose probability of success is ξ[i].\n",
    "# We record the result of inventing in xData. 0 in this case means either:\n",
    "#   i)  the agent tried inventing and failed, or\n",
    "#   ii) the agent did not try inventing. We need to look at dData to see why we observe 0 here.\n",
    "# To see what \".\" does, go to https://julia.quantecon.org/getting_started_julia/julia_by_example.html\n",
    "xData[:,1] = rand.(Bernoulli.(ξ)) .* dData[:,1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you might have noticed that in the static case, everyone makes the same choice! This is because in the first period, everyone has the same belief about their ability. As agents try out inventing and finds more about their ability, we will see that people making different choices.\n",
    "\n",
    "Given the data where everyone making the same choice (i.e., all zeros or all ones), we cannot point-identify **any** parameter of the set of parameters $(\\gamma,\\delta,w)$. Let's take a step back and look at the decision rule: \n",
    "$$\n",
    "d_t=\\begin{cases} 1 &\\text{ if } \\frac{\\gamma}{\\gamma+\\delta}>w \\\\ \n",
    "0  &\\text{ otherwise } \\end{cases}\n",
    "$$\n",
    "- If we are given the true value of one of $(\\gamma,\\delta,w)$, can you find the exact values for the rest of parameters? No. \n",
    "  - For example, let's say we are given $w=42$. What are the values of $\\gamma$ and $\\delta$ that can generate the data we have? All $(\\gamma,\\delta)$ that satisfy $\\frac{\\gamma}{\\gamma+\\delta}>42$.\n",
    "  - Since we have only one inequality and two parameters, we cannot point-identify $\\gamma$ and $\\delta$.\n",
    "- What if we are given two parameter values from $(\\gamma,\\delta,w)$? Can we point-identify the only left parameter? \n",
    "  - Again, as we are given an inequality, we can only find some bounds on the parameter we wish to identify. \n",
    "  - For example, if we are given $\\gamma=3$ and $\\delta=1$, then any $w$ that satisfies $\\frac{\\gamma}{\\gamma+\\delta}=\\frac{3}{4}>w$ can generate the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Dynamic Problem: 2 Periods](#dynamic2_menu)<a name=\"dynamic2periods\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve the two-period model. The lifetime utility is now $\\sum_{t=1}^{2} \\beta^{t-1} [d_t\\mathbf{1} \\{x_t=1\\} + (1-d_t)w]$. The state variables in each period are $(\\gamma_t,\\delta_t,w,t,\\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's solve this model by backward induction. At $t=2$, the agent observes $(\\gamma_{2},\\delta_{2},w,2,\\beta)$ and solves\n",
    "$$\n",
    "\\underset{d_{2}\\in\\{0,1\\}}{\\max}\\;\\mathbb{E}_{\\xi_2}\\Big[\\mathbb{E}_{x_2}\\big[d_2\\mathbf{1} \\{x_2=1\\} + (1-d_2)w\\big|\\xi_2\\big]\\Big|\\gamma_2,\\delta_2\\Big].\n",
    "$$\n",
    "It is straightforward that at $t=2$, the agent will choose to invent whenever the expected payoff of inventing is higher than choosing the outside option. We also derived that $\\mathbb{E}_{\\xi_2}\\Big[\\mathbb{E}_{x_2}\\big[\\mathbf{1}\\{x_{2}=1\\}\\big|\\xi_2\\big]\\Big|\\gamma_2,\\delta_2\\Big] = \\frac{\\gamma_2}{\\gamma_2 + \\delta_2}$. Thus, the decision rule at $t=2$ becomes:\n",
    "$\\begin{align*} \n",
    "    d_{2}(\\gamma_2,\\delta_2,w)=\\begin{cases}\n",
    "        1 & \\text{if } \\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\\\\n",
    "        0 & \\text{if } \\frac{\\gamma_2}{\\gamma_2 + \\delta_2}\\leq w\n",
    "    \\end{cases} = \\mathbf{1}\\left\\{\\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\right\\}.\n",
    "\\end{align*}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging the decision rule into the maximization problem, the expected value function at $t=2$ becomes:\n",
    "$$\\begin{align*} \n",
    "    V(\\gamma_2,\\delta_2,w,2,\\beta) &= \\underset{d_{2}\\in\\{0,1\\}}{\\max}\\;\\mathbb{E}_{\\xi_2}\\Big[\\mathbb{E}_{x_2}\\big[d_2\\mathbf{1} \\{x_2=1\\} + (1-d_2)w\\big|\\xi_2\\big]\\Big|\\gamma_2,\\delta_2\\Big] \\\\\n",
    "    &= d_2(\\gamma_2,\\delta_2,w)\\mathbb{E}_{\\xi_2}\\Big[\\mathbb{E}_{x_2}\\big[\\mathbf{1}\\{x_{2}=1\\}\\big|\\xi_2 \\big]\\Big|\\gamma_2,\\delta_2\\Big] + (1-d_2(\\gamma_2,\\delta_2,w))w \\\\\n",
    "    &= d_2(\\gamma_2,\\delta_2,w)\\frac{\\gamma_2}{\\gamma_2+\\delta_2} + (1-d_2(\\gamma_2,\\delta_2,w))w \\\\\n",
    "    &= \\mathbf{1}\\left\\{\\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\right\\} \\frac{\\gamma_2}{\\gamma_2+\\delta_2} + \\left(1-\\mathbf{1}\\left\\{\\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\right\\}\\right) w\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the decision rule $d_{2}(\\gamma_2,\\delta_2,w)$, we can solve for the agent's choice at $t=1$. At $t=1$, the agent maximizes her expectation of the discounted present value of the lifetime payoff:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    V(\\gamma_1,\\delta_1,w,1,\\beta) = \\underset{d_{1}\\in\\{0,1\\}}{\\max}\\; \\mathbb{E}_{\\xi_1}\\Big[&\\mathbb{E}_{x_1}[d_1\\mathbf{1}\\{x_{1}=1\\}+(1-d_{1})w|\\xi_1\\big]\\Big|\\gamma_1,\\delta_1\\Big] \\\\\n",
    "    +\\beta \\Bigg(&d_1\\mathbb{E}_{\\xi_1}\\Big[\\mathbb{E}_{x_1}\\Big[\\mathbf{1}\\{x_1=0|\\gamma_1,\\delta_1\\}V(\\gamma_2,\\delta_2,w,2)\\Big|\\xi_1\\Big]\\Big|\\gamma_1,\\delta_1\\Big]+\\\\\n",
    "                 &d_1\\mathbb{E}_{\\xi_1}\\Big[\\mathbb{E}_{x_1}\\Big[\\mathbf{1}\\{x_1=1|\\gamma_1,\\delta_1\\}V(\\gamma_2,\\delta_2,w,2)\\Big|\\xi_1\\Big]\\Big|\\gamma_1,\\delta_1\\Big]+\\\\\n",
    "                 &(1-d_1)V(\\gamma_2,\\delta_2,w,2)\\Bigg)\n",
    "\\end{align*}\n",
    "$$\n",
    "where $(\\gamma_2,\\delta_2)$ are updated by the following rule:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    (\\gamma_2,\\delta_2) = \\begin{cases}\n",
    "        (\\gamma_1+1, \\delta_1) &\\text{if } d_1=1, x_1 =1\\\\\n",
    "        (\\gamma_1, \\delta_1+1) &\\text{if } d_1=1, x_1 =0 \\\\\n",
    "        (\\gamma_1, \\delta_1) &\\text{if } d_1=0\n",
    "    \\end{cases}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that $\\mathbb{E}_{\\xi_1}[\\mathbb{P}[x_1=1|\\xi_1]\\big|\\gamma,\\delta]=\\frac{\\gamma}{\\gamma+\\delta}$ and $\\mathbb{E}_{\\xi_1}[\\mathbb{P}[x_1=0|\\xi_1]\\big|\\gamma,\\delta]=\\frac{\\delta}{\\gamma+\\delta}$, we rewrite the value function as:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "    V(\\gamma,\\delta,w,1,\\beta) = \\underset{d_{1}}{\\max}\\; d_{1}\\frac{\\gamma}{\\gamma+\\delta}+(1-d_{1})w +\\beta \\left[d_1\\frac{\\gamma}{\\gamma+\\delta}V(\\gamma+1,\\delta,w,2)+d_1\\frac{\\delta}{\\gamma+\\delta}V(\\gamma,\\delta+1,w,2)+(1-d_1)V(\\gamma,\\delta,w,2)\\right]\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use $V(\\gamma_2,\\delta_2,w,2,\\beta)=\\mathbf{1}\\left\\{\\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\right\\}\\cdot \\frac{\\gamma_2}{\\gamma_2+\\delta_2} + \\left(1-\\mathbf{1}\\left\\{\\frac{\\gamma_2}{\\gamma_2 + \\delta_2}> w\\right\\}\\right)\\cdot w$ to find the expression for $V(\\gamma,\\delta,w,1,\\beta)$ with only $\\gamma,\\delta,w$, and $d_1$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    V(\\gamma,\\delta,w,1,\\beta) = \\max_{d_{1}} \\; d_{1}\\frac{\\gamma}{\\gamma+\\delta}+(1-d_{1})w + \\beta\\bigg[&d_1\\frac{\\gamma}{\\gamma+\\delta}\\left(\\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\} \\frac{\\gamma+1}{\\gamma+\\delta+1} + \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\} w\\right)+\\\\\n",
    "    &d_1\\frac{\\delta}{\\gamma+\\delta}\\left(\\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}>w\\right\\} \\frac{\\gamma}{\\gamma+\\delta+1} + \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\} w\\right)+\\\\\n",
    "    &(1-d_1)\\left(\\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\} \\frac{\\gamma}{\\gamma+\\delta} + \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}\\leq w\\right\\} w\\right)\\bigg]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: we could write in this way only because we had two periods. If you have more than two periods you may want to prepare a mapping from a state space to the decision for each period. In this case, storing a function $d_t=\\mathbf{1}(\\gamma,\\delta,w,t)$ in a discretized state space for each time period $t$ may be necessary. If you have an infinite horizon, the dimension for time goes away and you may only need to find $d = \\mathbf{1}(\\gamma,\\delta,w)$, which we shall see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you find $w^*$, the upper bound of $w$, that ensures for every $w<w^*$, everyone invents in the first period? From the optimization problem in the first period, $d_1=1$ if the value of the value function when choosing $d_1=1$ is larger than or equal to that when choosing $d_1=0$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}+\\beta\\bigg[ &\\frac{\\gamma}{\\gamma+\\delta}\\left(\\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\} \\frac{\\gamma+1}{\\gamma+\\delta+1} + \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\} w\\right)+ \\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\left(\\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}> w\\right\\} \\frac{\\gamma}{\\gamma+\\delta+1} + \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\} w\\right)\\bigg] \\\\\n",
    "    &\\geq w+\\beta\\left(\\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\} \\frac{\\gamma}{\\gamma+\\delta} + \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}\\leq w\\right\\} w\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w$ is compared to three quantities $\\frac{\\gamma}{\\gamma+\\delta}$,$\\frac{\\gamma+1}{\\gamma+\\delta+1}$, $\\frac{\\gamma}{\\gamma+\\delta+1}$ inside the indicator functions. It is clear that $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}$. Thus, we have four cases to consider:\n",
    "\n",
    "1. $w<\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}\\leq w<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}\\leq w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $w<\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "    The following shows the values for indicator functions:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\}=0,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\}=0,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta} \\leq w \\right\\}=0\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Plugging these values into the inequality above, $d_1=1$ if:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}+\\beta\\bigg[\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}+\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\bigg] &\\geq w+\\beta\\bigg[\\frac{\\gamma}{\\gamma+\\delta}\\bigg]\\\\\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}&\\geq w\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Thus, if $w<\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}$, everyone will choose to invent.\n",
    "\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "    The following show the values for indicator functions:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\}=0,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\}=1,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta} \\leq w \\right\\}=0\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Plugging these values into the inequality above, $d_1=1$ if:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}+\\beta\\bigg[\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}+\\frac{\\delta}{\\gamma+\\delta}w\\bigg]&\\geq w+\\beta\\bigg[\\frac{\\gamma}{\\gamma+\\delta}\\bigg]\\\\\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}\\frac{1-\\frac{\\beta\\delta}{\\gamma+\\delta+1}}{1-\\frac{\\beta\\delta}{\\gamma+\\delta}}&\\geq w\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Thus, everyone will choose to invent if $\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w<\\min\\{\\frac{\\gamma}{\\gamma+\\delta},\\frac{\\gamma}{\\gamma+\\delta}\\frac{1-\\frac{\\beta\\delta}{\\gamma+\\delta+1}}{1-\\frac{\\beta\\delta}{\\gamma+\\delta}}\\}=\\frac{\\gamma}{\\gamma+\\delta}$\n",
    "\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}\\leq w<\\frac{\\gamma+1}{\\gamma+\\delta+1}$\n",
    "    The following show the values for indicator functions:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\}=1 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\}=0,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\}=1,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta} \\leq w \\right\\}=1\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Plugging these values into the inequality above, $d_1=1$ if:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}+\\beta\\bigg[ \\frac{\\gamma}{\\gamma+\\delta} \\frac{\\gamma+1}{\\gamma+\\delta+1} +\\frac{\\delta}{\\gamma+\\delta}  w \\bigg] &\\geq w+\\beta w \\\\\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}&\\geq w\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Thus, everyone will choose to invent if $\\frac{\\gamma}{\\gamma+\\delta}\\leq w<\\min\\{\\frac{\\gamma+1}{\\gamma+\\delta+1},\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}\\}=\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}$\n",
    "\n",
    "1. $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}\\leq w$\n",
    "    The following show the values for indicator functions:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma+\\delta+1}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma+1}{\\gamma + \\delta +1}\\leq w\\right\\}=1,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta +1}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma+\\delta+1}\\leq w\\right\\}=1,\\\\\n",
    "    \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta}> w\\right\\}=0 &\\text{ and } \\mathbf{1}\\left\\{\\frac{\\gamma}{\\gamma + \\delta} \\leq w \\right\\}=1\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    Plugging these values into the inequality above, $d_1=1$ if:\n",
    "    $$\n",
    "    \\begin{align*}\n",
    "    \\frac{\\gamma}{\\gamma+\\delta}+\\beta\\bigg[\\frac{\\gamma}{\\gamma+\\delta}w + \\frac{\\delta}{\\gamma+\\delta} w \\bigg] &\\geq \n",
    "    w+\\beta w \\\\\n",
    "    \\frac{\\gamma}{\\gamma+\\delta} &\\geq w\n",
    "    \\end{align*}\n",
    "    $$\n",
    "    We have contradiction: $\\frac{\\gamma}{\\gamma+\\delta+1}<w$ and $\\frac{\\gamma}{\\gamma+\\delta} \\geq w$. Thus, there is no $w$ that can make everyone choose $d_1=1$ if $\\frac{\\gamma}{\\gamma+\\delta+1}<\\frac{\\gamma}{\\gamma+\\delta}<\\frac{\\gamma+1}{\\gamma+\\delta+1}\\leq w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, everyone will choose to invent at $t=1$ if $w<\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}=w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code what we discussed so far. Instead of writing a bunch of indicator functions, I want to be lazy here and tell the program to find out the decision rule to the maximization problem on its own via backward induction. This is convenient because this allows us to easily extend the program to a finite horizon model with any size $T$.\n",
    "\n",
    "We start from the last period, $t=2$. In this period, we do not have any continuation value to think about; the maximization problem only has today's per-period utility. The value function and the policy function here are straightforward:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    V(\\gamma,\\delta,w,2,\\beta) &= \\underset{d\\in\\{0,1\\}}{\\max} \\quad\\; d \\frac{\\gamma}{\\gamma+\\delta}+ (1-d) w\\\\\n",
    "    d(\\gamma,\\delta,w,2,\\beta) &= \\underset{d\\in\\{0,1\\}}{\\arg\\max} \\; d \\frac{\\gamma}{\\gamma+\\delta}+ (1-d) w\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "The policy function and the value function at $t=1$ simply take the value function and the policy function we found at $t=2$ and return the solution and the maximized value to the maximization problem:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    V(\\gamma,\\delta,w,1,\\beta) = \\underset{d\\in\\{0,1\\}}{\\max} &d \\frac{\\gamma}{\\gamma+\\delta}+ (1-d) w + \\beta \\Bigg(d\\left(\\frac{\\gamma}{\\gamma+\\delta} V(\\gamma+1,\\delta,w,2,\\beta)+ \\frac{\\delta}{\\gamma+\\delta} V(\\gamma,\\delta+1,w,2,\\beta) \\right) + (1-d) V(\\gamma,\\delta,w,2,\\beta)\\Bigg) \\\\\n",
    "    d(\\gamma,\\delta,w,1,\\beta) = \\underset{d\\in\\{0,1\\}}{\\arg\\max} &d \\frac{\\gamma}{\\gamma+\\delta}+ (1-d) w + \\beta \\Bigg(d\\left(\\frac{\\gamma}{\\gamma+\\delta} V(\\gamma+1,\\delta,w,2,\\beta)+ \\frac{\\delta}{\\gamma+\\delta} V(\\gamma,\\delta+1,w,2,\\beta) \\right) + (1-d) V(\\gamma,\\delta,w,2,\\beta)\\Bigg) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Side note: you can \"solve and take note of\" the solution to the model by telling the program to return the decision at $t$ given state variables $(\\gamma,\\delta,w,\\beta)$ and store them in `DataFrames` or in an `Array` (memoization) while doing backward induction. I will not do that here because the computation is cheap in our case. You may want to do this when the state space or time horizon becomes large.\n",
    "\n",
    "Generating data based on this decision is also simple. \n",
    "- Set the number of agents $N$ and the initial state $(\\gamma,\\delta,w,\\beta)$. \n",
    "- Draw $\\xi$ from a Beta distribution $\\text{Beta}(\\gamma,\\delta)$ for each agent. \n",
    "- We ask the program what is the optimal decision for the agent with $(\\gamma,\\delta,w,\\beta)$ at $t=1$. In our model, everyone will make the same decision and so let's give the initial state so that everyone invents.\n",
    "- We store each agent's success/failure of inventing (we saw this in the static case). \n",
    "- We update the agents' belief about their ability. \n",
    "- We ask the program what is the optimal decision for the agent with $(\\gamma',\\delta',w,\\beta)$ at $t=2$ where $(\\gamma',\\delta',)$ are the updated beliefs about their ability.\n",
    "- Based on their optimal decision, let the agents invent or choose the outside option. \n",
    "- Store the result of invention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function u(j,γ,δ,w)\n",
    "    # Per-period utility function\n",
    "    return j * γ/(γ+δ) + (1-j) * w\n",
    "end\n",
    "\n",
    "function Val_2(γ,δ,w,t,β)\n",
    "    # The value function for the two-period model\n",
    "    # findmin(itr)[1] returns maximum value\n",
    "    if t==2\n",
    "        return findmax([u(j,γ,δ,w) for j=0:1])[1]\n",
    "    else\n",
    "        return findmax([u(j,γ,δ,w) + β*(j*(γ/(γ+δ) * Val_2(γ+1,δ,w,t+1,β) + δ/(γ+δ) * Val_2(γ,δ+1,w,t+1,β))+\n",
    "                                        (1-j)*Val_2(γ,δ,w,t+1,β)) for j=0:1])[1]\n",
    "    end\n",
    "end\n",
    "\n",
    "function d_dyn_2(γ,δ,w,t,β)\n",
    "    # The policy function for the two-period model\n",
    "    # findmin(itr)[2] is argmax. \"-1\" is there to match the index in Julia (1,2) to our choice index (0,1)\n",
    "    if t==2\n",
    "        return findmax([u(j,γ,δ,w) for j=0:1])[2]-1 \n",
    "    else\n",
    "        return findmax([u(j,γ,δ,w) + β*(j*(γ/(γ+δ) * Val_2(γ+1,δ,w,t+1,β) + δ/(γ+δ) * Val_2(γ,δ+1,w,t+1,β))+\n",
    "                                        (1-j)*Val_2(γ,δ,w,t+1,β)) for j=0:1])[2]-1\n",
    "    end\n",
    "end\n",
    "\n",
    "function simul_data(N,T,γ,δ,w,β)\n",
    "    γData = Array{Float64}(zeros(N,T));\n",
    "    δData = Array{Float64}(zeros(N,T));\n",
    "    dData = Array{Float64}(zeros(N,T));\n",
    "    xData = Array{Float64}(zeros(N,T));\n",
    "    \n",
    "    #=\n",
    "    Again, everyone has different ξ, but each person retains ξ over time (i.e., no learning by doing).\n",
    "    We only get to know 'how good we are' as we invent and observe outcomes.\n",
    "    =#\n",
    "    γData[:,1] .= γ;\n",
    "    δData[:,1] .= δ;\n",
    "    ξ = rand(Beta(γ,δ),N);\n",
    "\n",
    "    #=\n",
    "    broadcast() applies the function d_dyn_2 that takes 4 scalar arguments and\n",
    "    applies it element-wise over the vectors γData[:,1] and δData[:,1]\n",
    "    while fixing w,1,β as scalars.\n",
    "    =#\n",
    "    dData[:,1] = broadcast(d_dyn_2,γData[:,1],δData[:,1],w,1,β);\n",
    "    xData[:,1] = rand.(Bernoulli.(ξ)) .* dData[:,1];\n",
    "    for t=2:T\n",
    "        γData[:,t] .= γData[:,t-1] + dData[:,t-1] .* (1 .* xData[:,t-1])\n",
    "        δData[:,t] .= δData[:,t-1] + dData[:,t-1] .* (1 .* (1 .- xData[:,t-1]))\n",
    "        dData[:,t] .= broadcast(d_dyn_2,γData[:,t],δData[:,t],w,t,β)\n",
    "        xData[:,t] .= rand.(Bernoulli.(ξ)) .* dData[:,t];\n",
    "    end\n",
    "    return γData, δData, dData, xData, ξ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use $w^*=\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}$ and choice-specific conditional value function to check if our program is well-written. Choice-specific conditional value function is a discounted present value of lifetime utility if an agent commits to a certain choice today and behaves optimally in the periods that follow. In our case, there are two choice-specific conditional value functions at $t=1$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    v_0(\\gamma,\\delta,w,1,\\beta) &= w + \\beta V(\\gamma,\\delta,w,2,\\beta) \\\\\n",
    "    v_1(\\gamma,\\delta,w,1,\\beta) &= \\frac{\\gamma}{\\gamma+\\delta}+ \\beta \\Bigg(\\frac{\\gamma}{\\gamma+\\delta} V(\\gamma+1,\\delta,w,2,\\beta)+ \\frac{\\delta}{\\gamma+\\delta} V(\\gamma,\\delta+1,w,2,\\beta) \\Bigg)\n",
    "\\end{align*}\n",
    "$$\n",
    "We can put $w^*=\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}$ to our choice-specific conditional value functions and check if they have the same value, which is precisely what we expect from the definition of $w^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ=2.3; δ=2.0; β=0.96;\n",
    "w⃰ = (γ/(γ+δ))*(1+β*(γ+1)/(γ+δ+1))/(1+β*γ/(γ+δ))\n",
    "cvf = [(u(j,γ,δ,w⃰) + β*(j*(γ/(γ+δ) * Val_2(γ+1,δ,w⃰,2,β) + δ/(γ+δ) * Val_2(γ,δ+1,w⃰,2,β))+\n",
    "                        (1-j)*Val_2(γ,δ,w⃰,2,β))) for j=0:1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w⃰: 0.5646577217010124\n",
      "Choice-specific Conditional Value Function at t=1 when γ=2.3, δ=2.0, β=0.96, w=w⃰ \n",
      " - v₀(γ,δ,w⃰,1,β) = 1.106729134534 \n",
      " - v₁(γ,δ,w⃰,1,β) = 1.106729134534"
     ]
    }
   ],
   "source": [
    "# Print CVF when w=w⃰\n",
    "print(\"w⃰: \",w⃰,\"\\n\")\n",
    "print(\"Choice-specific Conditional Value Function at t=1 when γ=$γ, δ=$δ, β=$β, w=w⃰ \\n\")\n",
    "@printf(\" - v₀(γ,δ,w⃰,1,β) = %1.12f \\n\",cvf[1])\n",
    "@printf(\" - v₁(γ,δ,w⃰,1,β) = %1.12f\",cvf[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we only observe the agent's choice at $t = 2$. From the data, we can only talk about the fraction of agents quit inventing at $t=2$ condtional on the agents had tried inventing at $t=1$. Theoretically, we can think of the following cases:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbb{P}(d_2=0|d_1=1)=\\begin{cases}\n",
    "        0 &\\text{ if } w<w^* \\text{ and } w<\\frac{\\gamma}{\\gamma+\\delta+1}  \\\\\n",
    "        \\alpha &\\text{ if } w<w^* \\text{ and } \\frac{\\gamma}{\\gamma+\\delta+1}<w \\text{ where } \\alpha\\in(0,1) \\\\\n",
    "        1 &\\text{ if } w<w^* \\text{ and } w>\\frac{\\gamma+1}{\\gamma+\\delta+1}\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily show that the third case is impossible. Thus, we consider two cases:\n",
    "1. $\\mathbb{P}(d_2=0|d_1=1)=0$; i.e., we only observe ones in the data.\n",
    "    - This can happen if $w<w^*$ and $w<\\frac{\\gamma}{\\gamma+\\delta+1}$ (which implies $w<\\frac{\\gamma}{\\gamma+\\delta+1}$). We may only suggest some bounds to one of the parameters given specific values of the other parameters with this condition.\n",
    "    - For example, if we know exact values of $\\gamma$ and $\\delta$, we can only say that $w$ is less than $\\frac{\\gamma}{\\gamma+\\delta+1}$. Even then, any values of $\\beta\\in(0,1)$ can generate the same data so we cannot identify $\\beta$.\n",
    "1. $\\mathbb{P}(d_2=0|d_1=1)=\\alpha$; i.e., we observe some zeros and some ones in the data.\n",
    "    - This can happen if $w<w^*$ and $\\frac{\\gamma}{\\gamma+\\delta+1}<w$.\n",
    "    - If we are given the exact values of all but one of $(\\gamma,\\delta,w,\\beta)$, then how can we identify the remaining parameter?\n",
    "        - If we are asked to identify either $\\gamma$ or $\\delta$, then we can use our knowledge that $\\mathbb{E}[\\mathbf{1}\\{d_{2i}=1\\}]=\\frac{\\gamma}{\\gamma+\\delta}$ (details below).\n",
    "        - If we are asked to identify $w$ or $\\beta$, we can only identify up to some bounds:\n",
    "            - For $w$, we can only say that $\\frac{\\gamma}{\\gamma+\\delta+1}<w<\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}$.\n",
    "            - For $\\beta$, we can only say that $w<\\frac{\\gamma}{\\gamma+\\delta}\\frac{1+\\beta\\frac{\\gamma+1}{\\gamma+\\delta+1}}{1+\\beta\\frac{\\gamma}{\\gamma+\\delta}}$, i.e., $\\frac{(\\gamma+\\delta+1)(w\\gamma+w-\\gamma)}{\\gamma(\\gamma+1-w(\\gamma+\\delta+1))}<\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying $\\gamma$ or $\\delta$ is more interesting, so let's focus on identifying and estimating $\\gamma$ via MLE. Let's suppose we are given $(\\delta,w,\\beta,\\{d_{2i}\\}_{i=1}^N)$ and are asked to identify and estimate $\\gamma$. From the model, we know:\n",
    "$$\n",
    "    d_{2i}=\\mathbf{1} \\bigg\\{ \\mathbb{E}_{\\xi_2}\\bigg[\\mathbb{E}_{x_2}\\big[ \\mathbf{1}\\{x_2=1\\}\\big|\\xi_2\\big]\\Big|\\gamma,\\delta,x_1 \\bigg] > w \\bigg\\}\n",
    "$$\n",
    "i.e., $d_2$ is chosen by comparing the expected payoff of inventing which depends on our updated belief to the payoff of the outside option. The probability of observing $d_{2i}=1$, $\\mathbb{E}[\\mathbf{1}[d_{2i}=1]]$, is then:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbb{E} \\left[\\mathbf{1}[d_{2i}=1]\\right] =& \\mathbb{E} \\Bigg[\\mathbf{1} \\bigg\\{ \\mathbb{E}_{\\xi_2}\\Big[\\mathbb{E}_{x_2}\\big[ \\mathbf{1}\\{x_2=1\\}\\big|\\xi_2\\big]\\Big|\\gamma,\\delta,x_1 \\Big] > w \\bigg\\}\\Bigg] = \\mathbb{E} \\bigg[ \\mathbf{1} \\Big\\{ \\mathbb{E}_{\\xi_2}\\big[ 1\\cdot\\xi_{2}+0\\cdot(1-\\xi_{2})\\big|\\gamma,\\delta,x_1 \\big] > w \\Big\\} \\bigg] = \\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2} \\big[\\xi_{2};\\gamma,\\delta\\big] > w \\Big]\\\\\n",
    "    =& \\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2}\\big[\\xi_{2};\\gamma,\\delta,x_1\\big] > w \\big| d_{1}=1, x_1=1 \\Big] \\cdot \\mathbb{P} \\Big[ d_{1}=1, x_1=1 \\Big] + \\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2}\\big[\\xi_{2};\\gamma,\\delta,x_1\\big] > w \\big| d_{1}=1, x_1=0 \\Big] \\cdot \\mathbb{P} \\Big[ d_{1}=1, x_1=0 \\Big] \\\\\n",
    "    +& \\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2}\\big[\\xi_{2};\\gamma,\\delta,x_1\\big] > w \\big| d_{1}=0 \\Big] \\cdot \\mathbb{P} \\Big[ d_{1}=0 \\Big]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that $w<w^{*} \\implies d_1=1$. Since we are considering a dataset where we guarantee agents to invent in the first period, we have $\\mathbb{P}[d_1=0]=0.$ Thus, the following holds:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbb{E} \\left[\\mathbf{1}[d_{2i}=1]\\right] = &\\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2} \\big[ \\xi_{2}; \\gamma,\\delta,x_1 \\big] \\geq w \\bigm| d_{1}=1, x_1=1 \\Big] \\cdot \\mathbb{P} \\Big[d_{1}=1, x_1=1 \\Big]+ \\mathbb{P} \\Big[ \\mathbb{E}_{\\xi_2}\\big[\\xi_{2};\\gamma,\\delta,x_1\\big] \\geq w \\bigm| d_{1}=1, x_1=0 \\Big] \\cdot \\mathbb{P} \\Big[d_{1}=1, x_1=0 \\Big]\\\\\n",
    "    = &\\mathbb{P} \\bigg[ \\frac{\\gamma+1}{\\gamma+\\delta+1} \\geq w \\bigg] \\cdot  \\frac{\\gamma}{\\gamma+\\delta} + \\mathbb{P} \\bigg[ \\frac{\\gamma}{\\gamma+\\delta+1} \\geq w \\bigg] \\cdot  \\frac{\\delta}{\\gamma+\\delta} = \\frac{\\gamma}{\\gamma+\\delta} \\quad \\because w<w^*<\\frac{\\gamma+1}{\\gamma+\\delta+1} \\text{ and } \\frac{\\gamma}{\\gamma+\\delta+1}<w.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In words, we know that the agent would choose to invent in the second period if invention was successful in the first period. We also know that the probability of success follows a beta distribution $\\text{Beta}(\\gamma,\\delta)$ with expected value $\\frac{\\gamma}{\\gamma+\\delta}$. Thus, the likelihood of observing an agent inventing in the second period given $(\\gamma,\\delta)$ is $\\frac{\\gamma}{\\gamma+\\delta}$.\n",
    "\n",
    "The flipside of this argument is hazard rate at $t=2$. The probability of agent choosing to quit in the second period is $\\frac{\\delta}{\\gamma+\\delta}$. I suggest you use the similar reasoning I provided above and convince yourself that the hazard rate is indeed $\\frac{\\delta}{\\gamma+\\delta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discussion above motivates to construct the likelihood of $\\{d_{i2}\\}_{i=1}^{N}$ by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}(\\gamma;\\{d_{i2}\\}_{i=1}^{N},\\delta)=\\prod_{i=1}^{N}\\left(\\frac{\\gamma}{\\gamma+\\delta}\\right)^{d_{i2}}\\left(\\frac{\\delta}{\\gamma+\\delta}\\right)^{1-d_{i2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "The log-likelihood is\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\log\\mathcal{L}(\\gamma;\\{d_{i2}\\}_{i=1}^{N},\\delta)&=\\sum_{i=1}^{N}\\left(d_{i2}\\log\\left(\\frac{\\gamma}{\\gamma+\\delta}\\right)+(1-d_{i2})\\log\\left(\\frac{\\delta}{\\gamma+\\delta}\\right)\\right)\\\\\n",
    "    &=\\sum_{i=1}^{N}\\left(d_{i2}\\left(\\log\\gamma-\\log(\\gamma+\\delta)\\right)+(1-d_{i2})\\left(\\log\\delta-\\log(\\gamma+\\delta)\\right)\\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exploit that $\\{d_{i2}\\}_{i=1}^{N}$ are independent. The score function of a single observation $d_{i2}$ is\n",
    "$$\n",
    "\\begin{align*}\n",
    "    s(\\gamma;d_{i2},\\delta)=\\frac{\\partial}{\\partial\\gamma}\\log f(\\gamma;d_{i2},\\delta)=d_{i2}\\left(\\frac{1}{\\gamma}-\\frac{1}{\\gamma+\\delta}\\right)+(1-d_{i2})\\left(-\\frac{1}{\\gamma+\\delta}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "This gives us the derivative of the log-likelihood with respect to $\\gamma$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial}{\\partial\\gamma}\\log \\mathcal{L}(\\gamma;\\{d_{i2}\\}_{i=1}^{N},\\delta)=\\sum_{i=1}^{N}\\left(d_{i2}\\left(\\frac{1}{\\gamma}-\\frac{1}{\\gamma+\\delta}\\right)+(1-d_{i2})\\left(-\\frac{1}{\\gamma+\\delta}\\right)\\right)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting above to zero and solve for $\\gamma$ will give us the estimate of $\\gamma$ via MLE:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\sum_{i=1}^{N}\\left(d_{i2}\\left(\\frac{1}{\\gamma}-\\frac{1}{\\gamma+\\delta}\\right)+(1-d_{i2})\\left(-\\frac{1}{\\gamma+\\delta}\\right)\\right) &= 0 \\\\\n",
    "    \\left(\\frac{1}{\\gamma}-\\frac{1}{\\gamma+\\delta}\\right)\\sum_{i=1}^{N}d_{i2} -\\frac{N}{\\gamma+\\delta} + \\frac{1}{\\gamma+\\delta}\\sum_{i=1}^{N}d_{i2}&= 0 \\\\\n",
    "    \\frac{1}{\\gamma}\\sum_{i=1}^{N}d_{i2} = \\frac{N}{\\gamma+\\delta}&\\\\\n",
    "    \\therefore \\hat{\\gamma} = \\frac{\\delta\\sum_{i=1}^{N}d_{i2}}{N-\\sum_{i=1}^{N}d_{i2}}&\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\{d_{i2}\\}_{i=1}^{N}$ are i.i.d. so I use the following theorem to compute the Fisher information:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    I_{N}(\\gamma)&=N\\cdot I(\\gamma)=-N\\cdot \\mathbb{E}_{\\gamma}\\left(\\frac{\\partial^2\\log f(\\gamma;d_{i2},\\delta)}{\\partial \\gamma^2}\\right)\\\\\n",
    "    &=-N\\cdot\\mathbb{E}_{\\gamma}\\left( d_{i2}\\left(-\\frac{1}{\\gamma^2}+\\frac{1}{(\\gamma+\\delta)^2}\\right)+(1-d_{i2})\\left(\\frac{1}{(\\gamma+\\delta)^2}\\right)\\right)\\\\\n",
    "    &=-N\\cdot\\left(\\left(-\\frac{1}{\\gamma^2}+\\frac{1}{(\\gamma+\\delta)^2}\\right)\\frac{\\gamma}{\\gamma+\\delta}+\\left(\\frac{1}{(\\gamma+\\delta)^2}\\right)\\frac{\\delta}{\\gamma+\\delta}\\right) \\\\\n",
    "    &=\\frac{N\\delta}{\\gamma(\\gamma+\\delta)^2}\n",
    "\\end{align*}\n",
    "$$\n",
    "Substituting $\\gamma$ with $\\hat{\\gamma}$, we have asymptotic normality of the MLE as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    &\\hat{se} = \\sqrt{1/I_N(\\hat{\\gamma})}\\\\\n",
    "    &\\frac{\\hat{\\gamma}-\\gamma}{\\hat{se}} \\xrightarrow{d} N(0,1)\n",
    "\\end{align*}\n",
    "$$\n",
    "Coding the likelihood and the estimation routine based on our derivation is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function logLikelihood(γ,δ,dData)\n",
    "    γ = γ[1]\n",
    "    return -sum(dData[:,2].*(log(γ)-log(γ+δ)).+(1.0 .- dData[:,2]).*(log(δ)-log(γ+δ)))\n",
    "end\n",
    "\n",
    "function γ_estimation(δ,dData)\n",
    "    N = size(dData)[1]\n",
    "    γhat = (δ * sum(dData[:,2])) / (N-sum(dData[:,2]))\n",
    "    I   = δ / (γhat * (γhat+δ))\n",
    "    I_n = N * δ / (γhat*(γhat+δ)^2)\n",
    "    se  = sqrt(1 / I_n)\n",
    "    return γhat, se\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below shows the estimation result using various sample sizes. I also included using `Optim.jl`, a Julia package for various optimization routines to find the MLE estimate. As you can see, using `Optim.jl` returns the identical result as it should. Since analytically solving for the MLE as $T$ gets large in the finite horizon case or in the infinite horizon case is impossible, we will use `Optim.jl` in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(42)\n",
    "T=2;γ=3.0;δ=2.0;w=0.55;β=0.96;\n",
    "N_vec = [50,500,10_000,100_000,500_000]\n",
    "result_2 = Array{Float64}(zeros(length(N_vec),2,2))\n",
    "h_rate_2 = Vector{Float64}(zeros(length(N_vec)))\n",
    "_, _, dData, _, _ = simul_data(N_vec[end],T,γ,δ,w,β);\n",
    "for i=1:length(N_vec)\n",
    "    N = N_vec[i]\n",
    "    h_rate_2[i] = sum((dData[1:N,1].==1).&(dData[1:N,2].==0))/sum((dData[1:N,1].==1))\n",
    "    result_2[i,1,1], result_2[i,1,2] = γ_estimation(γ,δ,dData[1:N,:])\n",
    "    # We can also use Optim.jl to tell the program to find the MLE estimate for us\n",
    "    func = TwiceDifferentiable(x -> logLikelihood(x[1],δ,dData[1:N,:]),[1.0]);\n",
    "    optim = optimize(func,[1.0])\n",
    "    result_2[i,2,1] = optim.minimizer[1]\n",
    "    result_2[i,2,2] = sqrt(inv(Optim.hessian!(func,optim.minimizer)))[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Estimating γ in a Two-Period Model -----------------\n",
      "Parameters: γ=3.0, δ=2.0, w=0.55, β=0.96, T=2 \n",
      "Hazard Rate: Data vs Theory \n",
      "=====================================================================\n",
      "N     ||      50 |     500 |   10000 |  100000 |  500000 ||  Theory |\n",
      "h₂    || 0.42000 | 0.43200 | 0.40500 | 0.40036 | 0.39947 || 0.40000 |\n",
      "=====================================================================\n",
      "Estimation Result: \n",
      "=============================================================\n",
      "MLE \\ N  ||      50 |     500 |   10000 |  100000 |  500000 |\n",
      "-------------------------------------------------------------\n",
      "By hand  || 2.76190 | 2.62963 | 2.93827 | 2.99550 | 3.00663 |\n",
      "         ||(0.79138)|(0.23741)|(0.05986)|(0.01933)|(0.00868)|\n",
      "-------------------------------------------------------------\n",
      "Optim.jl || 2.76190 | 2.62963 | 2.93827 | 2.99550 | 3.00663 |\n",
      "         ||(0.79138)|(0.23741)|(0.05986)|(0.01933)|(0.00868)|\n",
      "=============================================================\n",
      "Standard errors in parentheses."
     ]
    }
   ],
   "source": [
    "# Print MLE estimation results\n",
    "print(\"---------------- Estimating γ in a Two-Period Model -----------------\\n\")\n",
    "print(\"Parameters: γ=$γ, δ=$δ, w=$w, β=$β, T=$T \\n\")\n",
    "@printf(\"Hazard Rate: Data vs Theory \\n\")\n",
    "print(\"=====================================================================\\n\")\n",
    "@printf(\"N     ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"|  Theory |\\n\") \n",
    "@printf(\"h₂    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_2[:]]; @printf(\"| %1.5f |\\n\",δ/(γ+δ))\n",
    "print(\"=====================================================================\\n\")\n",
    "\n",
    "@printf(\"Estimation Result: \\n\")\n",
    "print(\"=============================================================\\n\")\n",
    "@printf(\"MLE \\\\ N  ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"\\n\")\n",
    "print(\"-------------------------------------------------------------\\n\")\n",
    "@printf(\"By hand  ||\"); [@printf(\" %1.5f |\", i) for i in result_2[:,1,1]]; @printf(\"\\n\")\n",
    "@printf(\"         ||\"); [@printf(\"(%1.5f)|\", i) for i in result_2[:,1,2]]; @printf(\"\\n\")\n",
    "print(\"-------------------------------------------------------------\\n\")\n",
    "@printf(\"Optim.jl ||\"); [@printf(\" %1.5f |\", i) for i in result_2[:,2,1]]; @printf(\"\\n\")\n",
    "@printf(\"         ||\"); [@printf(\"(%1.5f)|\", i) for i in result_2[:,2,2]]; @printf(\"\\n\")\n",
    "print(\"=============================================================\\n\")\n",
    "@printf(\"Standard errors in parentheses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Dynamic Problem: Infinite Horizon](#dynamic_infty_menu)<a name=\"dynamic_infty\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that individuals live forever. The lifetime utility is now $\\sum_{t=1}^{\\infty}\\beta^{t-1}(d_t\\mathbf{1} \\{x_t=1\\} + (1-d_t)w)$.\n",
    "\n",
    "We consider the Bellman representation:\n",
    "$$\n",
    "\\begin{align*}\n",
    "V(\\gamma,\\delta,w,\\beta)=\\underset{d\\in\\{0,1\\}}{\\max}\\; d \\frac{\\gamma}{\\gamma+\\delta} + (1-d)w + \\beta \\left(d\\left(\\frac{\\gamma}{\\gamma+\\delta}V(\\gamma+1,\\delta,w,\\beta)+\\frac{\\delta}{\\gamma+\\delta}V(\\gamma,\\delta+1,w,\\beta)\\right)+(1-d)V(\\gamma,\\delta,w,\\beta)\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "The following code shows value function iteration (VFI) and data simulation.\n",
    "\n",
    "### VFI\n",
    "- Prepare a large enough grid of $\\gamma$ and $\\delta$ so that the value function is well-approximated for the infinite horizon case. In my code, I set the grid to be $(T+1)\\times(T+1)$ where $T$ is the time horizon I wish to solve the value function (100 is big enough, I think).\n",
    "- Make a guess for the value function. I chose $V(\\gamma,\\delta,w,\\beta)=\\frac{w}{1-\\beta}$ for all $\\gamma,\\delta$ (can you see why?)\n",
    "- With your initial guess, treat it as if it is indeed your value function. Put it on the RHS.\n",
    "- We will find a new value for the value function for all values of $\\gamma,\\delta$ in the grid by evaluating the Bellman representation. Note that if $\\gamma$ and $\\delta$ in the value function are on the boundary of the grid, we will tell the value function to not to increase the parameters (i.e., we are 'clipping' the grid of all possible values).\n",
    "- We just \"updated\" our value function!\n",
    "- Now, we have two value functions: our initial guess and the updated one. Are they significantly different? If so, toss the original guess and keep the updated one.\n",
    "- Put the updated one on the RHS in the Bellman representation and keep updating until the update is insignificant.\n",
    "- Contraction mapping theorem tells you that you can find the value function in this way.\n",
    "\n",
    "### Data simulation\n",
    "- Let's first decide the values for the known structural parameters, $\\gamma, \\delta, w$, and $\\beta$.\n",
    "- You got your value function from VFI. Now, you can find the policy function by finding the \"argmax\".\n",
    "- With the policy function, let's give $N$ agents some initial $\\gamma$ and $\\delta$. Based on your policy function, you can tell whether the agents will invent or not (let's make the data so that everyone invents in the first period).\n",
    "- Now, update the parameters based on the outcome of invention, and check with policy function what the agents will choose. Note also that I \"clipped\" the updating the parameters if the agent has reached to the boundary of the grid, but this will not really happen since I simulated the date up to $t=100$ so that even in the worst case the parameters are not on the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function VFI(γ,δ,w,β,T;print_flag=1)\n",
    "    γ_vec = collect(γ:γ+T);\n",
    "    δ_vec = collect(δ:δ+T);\n",
    "    V  = Matrix{Float64}( w/(1-β) .* ones(length(γ_vec),length(δ_vec)));\n",
    "    v₀ = Matrix{Float64}(zeros(length(γ_vec),length(δ_vec)));\n",
    "    v₁ = Matrix{Float64}(zeros(length(γ_vec),length(δ_vec)));\n",
    "    d  = Matrix{Float64}(zeros(length(γ_vec),length(δ_vec)));\n",
    "    max_distance = 1.0\n",
    "    euc_distance = 1.0\n",
    "    num_steps = 0\n",
    "    tol = 1e-16\n",
    "    max_steps = 2000\n",
    "    while (max_distance>tol && euc_distance>tol && num_steps<=2000)\n",
    "        # initialization\n",
    "        V_next = Matrix{Float64}(zeros(length(γ_vec),length(δ_vec)));\n",
    "        for i = 1:length(γ_vec)\n",
    "            for j = 1:length(δ_vec)\n",
    "                # we clip the value function if we reach the boundary of the grid\n",
    "                if i+1 < length(γ_vec)\n",
    "                    V_success = V[i+1,j]\n",
    "                else\n",
    "                    V_success = V[i,j]\n",
    "                end\n",
    "                if j+1 < length(δ_vec)\n",
    "                    V_fail = V[i,j+1]\n",
    "                else\n",
    "                    V_fail = V[i,j]\n",
    "                end\n",
    "                # Probability of success and fail\n",
    "                P_success = γ_vec[i]/(γ_vec[i]+δ_vec[j])\n",
    "                P_fail = δ_vec[j]/(γ_vec[i]+δ_vec[j])\n",
    "                # Conditional value functions\n",
    "                v₀[i,j] = w + β * V[i,j]\n",
    "                v₁[i,j] = γ_vec[i]/(γ_vec[i]+δ_vec[j]) + β * (P_success * V_success + P_fail * V_fail)\n",
    "            end\n",
    "        end\n",
    "        V_next = max.(v₀, v₁)\n",
    "        d      = (v₁.==V_next)\n",
    "        euc_distance = euclidean(V,V_next)\n",
    "        max_distance = maximum(abs.(V-V_next))\n",
    "        V = V_next\n",
    "        num_steps+=1\n",
    "        if (num_steps % 50==0) && (print_flag==1)\n",
    "            @printf(\"Step: %3i, Euclidean: %1.4e, Max: %1.4e \\n\",num_steps,euc_distance,max_distance)\n",
    "        end\n",
    "    end\n",
    "    if (num_steps<1000) && (print_flag==1)\n",
    "        @printf(\"VFI complete. It took %3i steps.\",num_steps)\n",
    "    end\n",
    "    if (num_steps==1000) && (print_flag==1)\n",
    "        @printf(\"VFI not completed. Euclidean: %1.4e, Max: %1.4e \\n\",euc_distance,max_distance)\n",
    "    end\n",
    "    \n",
    "    gr(fmt=png);\n",
    "    p1 = heatmap(δ_vec,γ_vec,d)\n",
    "    title!(\"Policy Function\")\n",
    "    xlabel!(L\"\\delta\")\n",
    "    ylabel!(L\"\\gamma\")\n",
    "    p2 = heatmap(δ_vec,γ_vec,V)\n",
    "    title!(\"Value function\")\n",
    "    xlabel!(L\"\\delta\")\n",
    "    ylabel!(L\"\\gamma\")\n",
    "    \n",
    "    fig=plot(p1, p2, label=[\"\" \"\"],size=(1200,500))\n",
    "\n",
    "    return v₀, v₁, V, d, fig\n",
    "end\n",
    "\n",
    "@everywhere function simul_data_infty(N,T,γ,δ,d)\n",
    "    \n",
    "    γData = Array{Float64}(zeros(N,T));\n",
    "    δData = Array{Float64}(zeros(N,T));\n",
    "    dData = Array{Float64}(zeros(N,T));\n",
    "    xData = Array{Float64}(zeros(N,T));\n",
    "    ξ = rand(Beta(γ,δ),N);\n",
    "    \n",
    "    γData[:,1] .= γ\n",
    "    δData[:,1] .= δ\n",
    "    γ_init = Int(floor(γ))-1\n",
    "    δ_init = Int(floor(δ))-1\n",
    "    \n",
    "    function decision(γ,δ,γ_init,δ_init)\n",
    "        γ = Int(floor(γ))\n",
    "        δ = Int(floor(δ))\n",
    "        return d[γ-γ_init,δ-δ_init]\n",
    "    end\n",
    "    \n",
    "    dData[:,1] = broadcast(decision,γData[:,1],δData[:,1],γ_init,δ_init)\n",
    "    xData[:,1] = rand.(Bernoulli.(ξ)) .* dData[:,1];\n",
    "\n",
    "    for t=2:T\n",
    "        γData[:,t] .= (γData[:,t-1].< γ+T) .* (γData[:,t-1] .+ 1 .* xData[:,t-1])         .+ (γData[:,t-1].>= γ+T) .* γData[:,t-1]\n",
    "        δData[:,t] .= (δData[:,t-1].< δ+T) .* (δData[:,t-1] .+ 1 .* (1 .- xData[:,t-1]))  .+ (δData[:,t-1].>= δ+T) .* δData[:,t-1]\n",
    "        dData[:,t] .= broadcast(decision,γData[:,t],δData[:,t],γ_init,δ_init)\n",
    "        xData[:,t] .= rand.(Bernoulli.(ξ)) .* dData[:,t];\n",
    "    end\n",
    "\n",
    "    return γData, δData, dData, xData, ξ\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set $\\gamma=2.3, \\delta=2.0, w=0.65, \\beta=0.96, N=100000$ here for an illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  50, Euclidean: 1.0882e+00, Max: 4.3294e-02 \n",
      "Step: 100, Euclidean: 1.1451e-01, Max: 5.3323e-03 \n",
      "Step: 150, Euclidean: 1.1084e-02, Max: 6.3784e-04 \n",
      "Step: 200, Euclidean: 1.0214e-03, Max: 7.3033e-05 \n",
      "Step: 250, Euclidean: 8.8779e-05, Max: 7.8271e-06 \n",
      "Step: 300, Euclidean: 7.1427e-06, Max: 7.5905e-07 \n",
      "Step: 350, Euclidean: 5.2375e-07, Max: 6.4415e-08 \n",
      "Step: 400, Euclidean: 3.4869e-08, Max: 4.7434e-09 \n",
      "Step: 450, Euclidean: 2.1278e-09, Max: 3.0889e-10 \n",
      "Step: 500, Euclidean: 1.2108e-10, Max: 1.8325e-11 \n",
      "Step: 550, Euclidean: 6.5458e-12, Max: 1.0161e-12 \n",
      "Step: 600, Euclidean: 3.4281e-13, Max: 6.0396e-14 \n",
      "Step: 650, Euclidean: 2.8422e-14, Max: 1.4211e-14 \n",
      "Step: 700, Euclidean: 3.5527e-15, Max: 3.5527e-15 \n",
      "VFI complete. It took 706 steps.  7.549281 seconds (16.46 M allocations: 1.194 GiB, 3.37% gc time, 52.19% compilation time)\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(42)\n",
    "γ=2.3;δ=2.0;w=0.65;β=0.96;N=100_000;T=100;\n",
    "@time v₀, v₁, V, d, fig = VFI(γ,δ,w,β,T);\n",
    "γData, δData, dData, xData, ξ = simul_data_infty(N,T,γ,δ,d);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the policy function and the value function we found via VFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figures for the Policy/Value Functions\n",
    "Plots.savefig(fig,\"value_policy_dyn_infty\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures below are the fraction of agents trying at $t$ and the hazard rate at $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figures for Survival/Harard Rates\n",
    "t = 1:T;\n",
    "s = vec(sum(dData,dims=1)/N)[1:T];\n",
    "h = vcat(0, reduce(vcat,(sum(dData[:,t-1])-sum(dData[:,t]))/sum(dData[:,t-1]) for t=2:T));\n",
    "survival_fig = plot(t,s,lab=\"Survival rate\")\n",
    "title!(L\"\\textrm{Fraction of Agents Survived until } t\")\n",
    "xaxis!(L\"t\")\n",
    "yaxis!(L\"\\textrm{Fraction}\")\n",
    "hazard_fig   = plot(t,h,lab=\"Hazard rate\")\n",
    "title!(L\"\\textrm{Quitting at } t \\textrm{ Conditional on Trying Until } t\")\n",
    "xaxis!(L\"t\")\n",
    "yaxis!(L\"\\textrm{Fraction}\")\n",
    "survival_hazard = plot(survival_fig, hazard_fig, label=[\"\" \"\"], size=(1200,500))\n",
    "Plots.savefig(survival_hazard,\"survival_hazard_rate\")\n",
    "survival_hazard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hazard Rate and MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "- $h_t(\\gamma,\\delta)$: The probability that a spell ends at $t$ conditional on surviving up to $t$ given the initial state $(\\gamma,\\delta)$. In other words, the agents started with $(\\gamma,\\delta)$ and tried inventing up to $t-1$, and decided to quit at $t$.\n",
    "- $d(\\gamma,\\delta)$: The decision rule that tells the agent to invent given $(\\gamma,\\delta)$; i.e., $\\mathbf{1}\\{v_1(\\gamma,\\delta)>v_0(\\gamma,\\delta)\\}$.\n",
    "- S: Tried inventing and succeeded, F: Tried inventing and failed, Q: Quit inventing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    h_1(\\gamma,\\delta)=&\\mathbb{P}(\\text{The agent quits at }t=1)\\\\\n",
    "        =&\\mathbb{E}(1-d(\\gamma,\\delta))\n",
    "\\end{align*}\n",
    "$$\n",
    "We are going to generate the data so that everyone tries inventing at $t=1$, so $h_1(\\gamma,\\delta)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align*}\n",
    "    h_2(\\gamma,\\delta)=&\\mathbb{P}(\\text{The agent quits at }t=2|\\text{The agent invents until } t=1 )\\\\\n",
    "    =&\\frac{\\mathbb{P}(\\text{The agent invents until } t=1 \\text{ and quits at }t=2)}{\\mathbb{P}(\\text{The agent invents until } t=1 )} = \\frac{\\mathbb{P}(\\text{The agent invents until } t=1 \\text{ and quits at }t=2)}{1-h_1}\\\\\n",
    "    =&\\frac{1}{1-h_1}\\Bigg(\\mathbb{P}(\\text{S,Q}) + \\mathbb{P}(\\text{F,Q})\\Bigg)\\\\\n",
    "    =&\\frac{1}{1-h_1}\\Bigg(\\frac{\\gamma}{\\gamma+\\delta}d(\\gamma,\\delta)\\Big(1-d(\\gamma+1,\\delta)\\Big)+\\frac{\\delta}{\\gamma+\\delta}d(\\gamma,\\delta)\\Big(1-d(\\gamma,\\delta+1)\\Big)\\Bigg)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    h_3(\\gamma,\\delta) =&\\mathbb{P}(\\text{The agent quits at }t=3|\\text{The agent invents until } t=2)\\\\\n",
    "    =&\\frac{\\mathbb{P}(\\text{The agent invents until } t=2 \\text{ and quits at }t=3)}{\\mathbb{P}(\\text{The agent invents until } t=2 )} = \\frac{\\mathbb{P}(\\text{The agent invents until } t=2 \\text{ and quits at }t=3)}{(1-h_1)(1-h_2)}\\\\\n",
    "    =&\\frac{1}{(1-h_1)(1-h_2)}\\Bigg(\\mathbb{P}(\\text{S,S,Q})+\\mathbb{P}(\\text{S,F,Q})+\\mathbb{P}(\\text{F,S,Q})+\\mathbb{P}(\\text{F,F,Q})\\Bigg) \\\\\n",
    "    =&\\frac{1}{(1-h_1)(1-h_2)}\\times\\\\\n",
    "    \\Bigg(&\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}d(\\gamma,\\delta)d(\\gamma+1,\\delta)\\Big(1-d(\\gamma+2,\\delta)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}d(\\gamma,\\delta)d(\\gamma+1,\\delta)\\Big(1-d(\\gamma+1,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}d(\\gamma,\\delta)d(\\gamma,\\delta+1)\\Big(1-d(\\gamma+1,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}d(\\gamma,\\delta)d(\\gamma,\\delta+1)\\Big(1-d(\\gamma,\\delta+2)\\Big)\\Bigg)\n",
    "\\end{align*}\n",
    "$$\n",
    "Notice that at $t=3$, the proportion who tried until $t=2$ is $(1-h_1)(1-h_2)=1-h_2$. Also, the fractions inside represent the proportions of the population of agents who survived until $t=2$ and quits at $t=3$ for every possible history until $t=2$. Directly counting all possible history like this is possible only because the states are discretized. Although the summation will get more complicated, let's do this approach upto $t=5$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    h_4(\\gamma,\\delta) =& \\mathbb{P}(\\text{The agent quits at }t=4|\\text{The agent invents until }t=3)\\\\\n",
    "    =&\\frac{\\mathbb{P}(\\text{The agent invents until }t=3\\text{ and quits at }t=4)}{\\mathbb{P}(\\text{The agent invents until }t=3)} =\\frac{\\mathbb{P}(\\text{The agent invents until }t=3\\text{ and quits at }t=4)}{(1-h_1)(1-h_2)(1-h_3)}\\\\\n",
    "    =&\\frac{1}{(1-h_1)(1-h_2)(1-h_3)}\\times\\\\\n",
    "    \\Bigg(&\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\gamma+2}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)\\Big(1-d(\\gamma+3,\\delta)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\delta}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)\\Big(1-d(\\gamma+2,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)\\Big(1-d(\\gamma+2,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)\\Big(1-d(\\gamma+2,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}\\frac{\\gamma}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+1)\\Big(1-d(\\gamma+1,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)\\Big(1-d(\\gamma+1,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)\\Big(1-d(\\gamma+1,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\gamma+2}{\\gamma+\\delta+2}d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+2)\\Big(1-d(\\gamma,\\delta+3)\\Big)\\Bigg)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    h_5(\\gamma,\\delta) =& \\mathbb{P}(\\text{The agent quits at }t=5|\\text{The agent invents until }t=4) \\\\\n",
    "    =&\\frac{\\mathbb{P}(\\text{The agent invents until }t=4\\text{ and quits at }t=5)}{\\mathbb{P}(\\text{The agent invents until }t=4)} = \\frac{\\mathbb{P}(\\text{The agent invents until }t=4\\text{ and quits at }t=5)}{(1-h_1)(1-h_2)(1-h_3)(1-h_4)}\\\\\n",
    "    =&\\frac{1}{(1-h_1)(1-h_2)(1-h_3)(1-h_4)}\\times\\\\\n",
    "    \\Bigg(&\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\gamma+2}{\\gamma+\\delta+2}\\frac{\\gamma+3}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)d(\\gamma+3,\\delta)\\Big(1-d(\\gamma+4,\\delta)\\Big)+\\\\\n",
    "        \n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\gamma+2}{\\gamma+\\delta+2}\\frac{\\delta}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)d(\\gamma+3,\\delta)\\Big(1-d(\\gamma+3,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\delta}{\\gamma+\\delta+2}\\frac{\\gamma+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+3,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}\\frac{\\gamma+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+3,\\delta+1)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}\\frac{\\gamma+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+3,\\delta+1)\\Big)+\\\\\n",
    "\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\gamma+1}{\\gamma+\\delta+1}\\frac{\\delta}{\\gamma+\\delta+2}\\frac{\\delta+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+2,\\delta)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}\\frac{\\delta+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}\\frac{\\gamma+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}\\frac{\\gamma}{\\gamma+\\delta+2}\\frac{\\gamma+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+2)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}\\frac{\\gamma+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\gamma+1}{\\gamma+\\delta+2}\\frac{\\delta+1}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)d(\\gamma+2,\\delta+1)\\Big(1-d(\\gamma+2,\\delta+2)\\Big)+\\\\\n",
    "\n",
    "    &\\frac{\\gamma}{\\gamma+\\delta}\\frac{\\delta}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}\\frac{\\delta+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma+1,\\delta)d(\\gamma+1,\\delta+1)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+1,\\delta+3)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\gamma}{\\gamma+\\delta+1}\\frac{\\delta+1}{\\gamma+\\delta+2}\\frac{\\delta+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma+1,\\delta+1)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+1,\\delta+3)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}\\frac{\\gamma}{\\gamma+\\delta+2}\\frac{\\delta+2}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+2)d(\\gamma+1,\\delta+2)\\Big(1-d(\\gamma+1,\\delta+3)\\Big)+\\\\\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}\\frac{\\delta+2}{\\gamma+\\delta+2}\\frac{\\gamma}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+2)d(\\gamma,\\delta+3)\\Big(1-d(\\gamma+1,\\delta+3)\\Big)+\\\\\n",
    "\n",
    "    &\\frac{\\delta}{\\gamma+\\delta}\\frac{\\delta+1}{\\gamma+\\delta+1}\\frac{\\delta+2}{\\gamma+\\delta+2}\\frac{\\delta+3}{\\gamma+\\delta+3}\n",
    "        d(\\gamma,\\delta)d(\\gamma,\\delta+1)d(\\gamma,\\delta+2)d(\\gamma,\\delta+3)\\Big(1-d(\\gamma,\\delta+4)\\Big)\\Bigg) \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this into a function and call it `hazard`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function hazard(d, γ, δ)\n",
    "    h₁ = 1-d[1,1]\n",
    "    h₂ = 1/(1-h₁) * (\n",
    "            d[1,1] * γ/(γ+δ) * (1-d[2,1]) +\n",
    "            d[1,1] * δ/(γ+δ) * (1-d[1,2])\n",
    "        ) \n",
    "    h₃ = 1/(1-h₁) * 1/(1-h₂) * (\n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * (1-d[3,1])    +\n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * (1-d[2,2])    + \n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * (1-d[2,2])    +\n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * (1-d[1,3])\n",
    "        ) \n",
    "    h₄ = 1/(1-h₁) * 1/(1-h₂) * 1/(1-h₃) * (\n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (γ+2)/(γ+δ+2) * (1-d[4,1]) +\n",
    "            \n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (δ  )/(γ+δ+2) * (1-d[3,2]) +\n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * (1-d[3,2]) +\n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * (1-d[3,2]) +\n",
    "    \n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * (1-d[2,3]) +\n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * (1-d[2,3]) +\n",
    "            d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * (1-d[2,3]) +\n",
    "    \n",
    "            d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * (1-d[1,4])\n",
    "        )\n",
    "    h₅ = 1/(1-h₂) * 1/(1-h₃) * 1/(1-h₄)*(\n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (γ+2)/(γ+δ+2) * d[4,1] * (γ+3)/(γ+δ+3) * (1-d[5,1]) +\n",
    "            \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (γ+2)/(γ+δ+2) * d[4,1] * (δ  )/(γ+δ+3) * (1-d[4,2]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (δ  )/(γ+δ+2) * d[3,2] * (γ+2)/(γ+δ+3) * (1-d[4,2]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * d[3,2] * (γ+2)/(γ+δ+3) * (1-d[4,2]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * d[3,2] * (γ+2)/(γ+δ+3) * (1-d[4,2]) +\n",
    "    \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (γ+1)/(γ+δ+1) * d[3,1] * (δ  )/(γ+δ+2) * d[3,2] * (δ+1)/(γ+δ+3) * (1-d[3,3]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * d[3,2] * (δ+1)/(γ+δ+3) * (1-d[3,3]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * d[2,3] * (γ+1)/(γ+δ+3) * (1-d[3,3]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * d[2,3] * (γ+1)/(γ+δ+3) * (1-d[3,3]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * d[2,3] * (γ+1)/(γ+δ+3) * (1-d[3,3]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (γ+1)/(γ+δ+2) * d[3,2] * (δ+1)/(γ+δ+3) * (1-d[3,3]) +\n",
    "    \n",
    "        d[1,1] * γ/(γ+δ) * d[2,1] * (δ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * d[2,3] * (δ+2)/(γ+δ+3) * (1-d[2,4]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,2] * (δ+1)/(γ+δ+2) * d[2,3] * (δ+2)/(γ+δ+3) * (1-d[2,4]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * d[2,3] * (δ+2)/(γ+δ+3) * (1-d[2,4]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * d[1,4] * (γ  )/(γ+δ+3) * (1-d[2,4]) +\n",
    "        \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * d[1,4] * (δ+3)/(γ+δ+3) * (1-d[1,5])\n",
    "    )\n",
    "      return h₁, h₂, h₃, h₄, h₅\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to use these hazard rates and do MLE like in the two-period model. The sample comprises a cross section of spells $i\\in\\{1,\\ldots,N\\}$, some of which are completed at $\\tau_i$, and some of which are incomplete lasting at least $T$ periods. Let $p_{\\tau}(\\gamma;\\delta)$ denote the unconditional probability of individual $i$ with parameters $(\\gamma,\\delta)$ inventing for $\\tau-1$ periods and stop inventing at $\\tau$ if spell is complete and the unconditional probability of individual $i$ inventing for at least $\\tau$ periods if spell is incomplete:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p_{i}(\\gamma;\\delta) := \\begin{cases}\n",
    "    h_{\\tau_i}(\\gamma,\\delta)\\prod_{s=1}^{\\tau_i-1}(1-h_s(\\gamma,\\delta)) &\\text{ if spell is complete}\\\\\n",
    "    \\prod_{s=1}^{T}(1-h_s(\\gamma,\\delta)) & \\text{ if spell is incomplete}\n",
    "    \\end{cases}\n",
    "$$\n",
    "The likelihood is then:\n",
    "$$\\begin{align*}\n",
    "    \\mathcal{L}&=\\prod_{i=1}^{N}p_{\\tau_i}(\\gamma;\\delta)\\\\\n",
    "    \\log\\mathcal{L}&=\\sum_{i=1}^{N}\\log p_{\\tau_i}(\\gamma;\\delta)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are playing with this model, we can think about this question: how much do our MLE estimates improve as i) N increases and ii) T increases in our data? If we have more information about what agents do in the future, can we estimate our parameter better? In order to see this, I will form the log-likelihood supposing that we have data up to $t=2,3,4,5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function logLikelihood_infty(log_γ,δ,w,β,T,qData,time)\n",
    "      γ = exp(log_γ[1])\n",
    "      v₀, v₁, _, _, _= VFI(γ,δ,w,β,T,print_flag=0);\n",
    "      h₁, h₂, h₃, h₄, h₅ = hazard(d, γ, δ)\n",
    "      if time ==2 \n",
    "            return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                             (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                             (qData.==2).*(1-h₁).*(1-h₂)))\n",
    "      elseif time ==3\n",
    "            return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                             (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                             (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+ \n",
    "                             (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃)))\n",
    "      elseif time ==4\n",
    "            return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                             (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                             (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+\n",
    "                             (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃).*(  h₄) .+\n",
    "                             (qData.==4).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄))) \n",
    "      else # time ==5 \n",
    "            return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                             (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                             (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+\n",
    "                             (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃).*(  h₄) .+\n",
    "                             (qData.==4).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄).*(  h₅) .+\n",
    "                             (qData.==5).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄).*(1-h₅)))\n",
    "      end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function simul_data_infty(N,T,γ,δ,d,Tdata)\n",
    "    # N: the number of agents\n",
    "    # T: the time horizon we wish to do VFI\n",
    "    # γ, δ: structural parameters\n",
    "    # d: decision rule\n",
    "    # Tdata: the last time period we wish to simulate data\n",
    "    γData = Array{Float64}(zeros(N,Tdata));\n",
    "    δData = Array{Float64}(zeros(N,Tdata));\n",
    "    dData = Array{Float64}(zeros(N,Tdata));\n",
    "    xData = Array{Float64}(zeros(N,Tdata));\n",
    "    ξ = rand(Beta(γ,δ),N);\n",
    "    \n",
    "    γData[:,1] .= γ\n",
    "    δData[:,1] .= δ\n",
    "    γ_init = Int(floor(γ))-1\n",
    "    δ_init = Int(floor(δ))-1\n",
    "    \n",
    "    function decision(γ,δ,γ_init,δ_init)\n",
    "        γ = Int(floor(γ))\n",
    "        δ = Int(floor(δ))\n",
    "        return d[γ-γ_init,δ-δ_init]\n",
    "    end\n",
    "    \n",
    "    dData[:,1] = broadcast(decision,γData[:,1],δData[:,1],γ_init,δ_init)\n",
    "    xData[:,1] = rand.(Bernoulli.(ξ)) .* dData[:,1];\n",
    "\n",
    "    for t=2:Tdata\n",
    "        γData[:,t] = (dData[:,t-1].==1) .* ((γData[:,t-1].< γ+T) .* (γData[:,t-1] .+ 1 .* xData[:,t-1]) .+ (γData[:,t-1].>= γ+T) .* γData[:,t-1]) +\n",
    "                     (dData[:,t-1].==0) .* γData[:,t-1]\n",
    "        δData[:,t] = (dData[:,t-1].==1) .* ((δData[:,t-1].< δ+T) .* (δData[:,t-1] .+ 1 .* (1 .- xData[:,t-1]))  .+ (δData[:,t-1].>= δ+T) .* δData[:,t-1]) +\n",
    "                     (dData[:,t-1].==0) .* δData[:,t-1]\n",
    "        dData[:,t] = broadcast(decision,γData[:,t],δData[:,t],γ_init,δ_init)\n",
    "        xData[:,t] = rand.(Bernoulli.(ξ)) .* dData[:,t];\n",
    "    end\n",
    "\n",
    "    return γData, δData, dData, xData, ξ\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 9:\tN= 500000 using information up to t=2 is done! \n",
      "      From worker 6:\tN=    500 using information up to t=2 is done! \n",
      "      From worker 10:\tN=5000000 using information up to t=2 is done! \n",
      "      From worker 7:\tN=   5000 using information up to t=2 is done! \n",
      "      From worker 8:\tN=  50000 using information up to t=2 is done! \n",
      "      From worker 9:\tN= 500000 using information up to t=3 is done! \n",
      "      From worker 6:\tN=    500 using information up to t=3 is done! \n",
      "      From worker 10:\tN=5000000 using information up to t=3 is done! \n",
      "      From worker 9:\tN= 500000 using information up to t=4 is done! \n",
      "      From worker 6:\tN=    500 using information up to t=4 is done! \n",
      "      From worker 7:\tN=   5000 using information up to t=3 is done! \n",
      "      From worker 8:\tN=  50000 using information up to t=3 is done! \n",
      "      From worker 10:\tN=5000000 using information up to t=4 is done! \n",
      "      From worker 6:\tN=    500 using information up to t=5 is done! \n",
      "      From worker 9:\tN= 500000 using information up to t=5 is done! \n",
      "      From worker 7:\tN=   5000 using information up to t=4 is done! \n",
      "      From worker 8:\tN=  50000 using information up to t=4 is done! \n",
      "      From worker 7:\tN=   5000 using information up to t=5 is done! \n",
      "      From worker 10:\tN=5000000 using information up to t=5 is done! \n",
      "      From worker 8:\tN=  50000 using information up to t=5 is done! \n",
      "367.521465 seconds (46.52 k allocations: 2.655 MiB, 0.01% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000000ea2b3a0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_vec = [500,5_000,50_000,500_000,5_000_000];Tdata=5;\n",
    "_, _, dData, _, _ = simul_data_infty(N_vec[end],T,γ,δ,d,Tdata);\n",
    "h₁, h₂, h₃, h₄, h₅ = hazard(d, γ, δ)\n",
    "\n",
    "@everywhere begin\n",
    "    γ=2.3;δ=2.0;w=0.65;β=0.96;T=100;\n",
    "    v₀, v₁, V, d, _ = VFI(γ,δ,w,β,T,print_flag=0);\n",
    "    Random.seed!(42)    \n",
    "    deviation = randn()\n",
    "    γ_init = [log(γ+deviation/2)]\n",
    "    lb, ub = log(0.1), log(γ+abs(deviation+2))\n",
    "    lb_ub = TwiceDifferentiableConstraints([lb],[ub]);\n",
    "end\n",
    "\n",
    "h_rate_infty = SharedArray{Float64}(zeros(length(N_vec),4));\n",
    "result_infty = SharedArray{Float64}(zeros(length(N_vec),4,2));\n",
    "\n",
    "@time @sync @distributed for i = 1:length(N_vec)\n",
    "    N = N_vec[i]\n",
    "    h_rate_infty[i,1] = sum((dData[1:N,1].==1).&(dData[1:N,2].==0))/sum((dData[1:N,1].==1))\n",
    "    h_rate_infty[i,2] = sum((dData[1:N,2].==1).&(dData[1:N,3].==0))/sum((dData[1:N,2].==1))\n",
    "    h_rate_infty[i,3] = sum((dData[1:N,3].==1).&(dData[1:N,4].==0))/sum((dData[1:N,3].==1))\n",
    "    h_rate_infty[i,4] = sum((dData[1:N,4].==1).&(dData[1:N,5].==0))/sum((dData[1:N,4].==1))\n",
    "    for t = 2:Tdata\n",
    "        qData = sum(dData[1:N,1:t],dims=2);\n",
    "        func = TwiceDifferentiable(γ -> logLikelihood_infty(γ[1],δ,w,β,T,qData,t),[γ]);\n",
    "        opt = optimize(func, lb_ub, γ_init, IPNewton())\n",
    "        @printf(\"N=%7i using information up to t=%1i is done! \\n\",N,t)\n",
    "        γ_hat_optim = exp(opt.minimizer[1])\n",
    "        σ_hat_optim = sqrt(inv(hessian!(func,opt.minimizer)))[1]\n",
    "        result_infty[i,t-1,1] = γ_hat_optim\n",
    "        result_infty[i,t-1,2] = σ_hat_optim\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Estimating γ in an Infinite Horizon Model -------------\n",
      "Parameters: γ=2.3, δ=2.0, w=0.65, β=0.96 \n",
      "Initial Point: 2.0220, Lower bound  : 0.1000, Upper bound: 3.7440 \n",
      "Hazard Rate: Data vs Theory \n",
      "=====================================================================\n",
      "N     ||     500 |    5000 |   50000 |  500000 | 5000000 ||  Theory |\n",
      "---------------------------------------------------------------------\n",
      "h₂    || 0.46800 | 0.47360 | 0.47024 | 0.46538 | 0.46521 || 0.46512 |\n",
      "h₃    || 0.00000 | 0.00000 | 0.00000 | 0.00000 | 0.00000 || 0.00000 |\n",
      "h₄    || 0.18797 | 0.16945 | 0.17831 | 0.18040 | 0.17955 || 0.17969 |\n",
      "h₅    || 0.24537 | 0.20082 | 0.19435 | 0.19763 | 0.19779 || 0.19805 |\n",
      "=====================================================================\n",
      "Estimation Result: \n",
      "==============================================================\n",
      "Data \\ N  ||     500 |    5000 |   50000 |  500000 | 5000000 |\n",
      "--------------------------------------------------------------\n",
      "Up to t=2 || 2.27350 | 2.22297 | 2.25315 | 2.29756 | 2.29911 |\n",
      "          ||(0.08963)|(0.02832)|(0.00896)|(0.00284)|(0.00090)|\n",
      "Up to t=3 || 2.27350 | 2.22297 | 2.25315 | 2.29756 | 2.29911 |\n",
      "          ||(0.08963)|(0.02832)|(0.00896)|(0.00284)|(0.00090)|\n",
      "Up to t=4 || 2.24975 | 2.27689 | 2.26876 | 2.29550 | 2.29987 |\n",
      "          ||(0.07853)|(0.02500)|(0.00788)|(0.00249)|(0.00079)|\n",
      "Up to t=5 || 2.16508 | 2.27365 | 2.27950 | 2.29683 | 2.30043 |\n",
      "          ||(0.07395)|(0.02365)|(0.00746)|(0.00235)|(0.00074)|\n",
      "==============================================================\n",
      "Standard errors in parentheses."
     ]
    }
   ],
   "source": [
    "# Print MLE estimation results\n",
    "print(\"------------ Estimating γ in an Infinite Horizon Model -------------\\n\")\n",
    "print(\"Parameters: γ=$γ, δ=$δ, w=$w, β=$β \\n\")\n",
    "@printf(\"Initial Point: %1.4f, Lower bound  : %1.4f, Upper bound: %1.4f \\n\", exp(γ_init[1]), exp(lb), exp(ub))\n",
    "@printf(\"Hazard Rate: Data vs Theory \\n\")\n",
    "print(\"=====================================================================\\n\")\n",
    "@printf(\"N     ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"|  Theory |\\n\") \n",
    "print(\"---------------------------------------------------------------------\\n\")\n",
    "@printf(\"h₂    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_infty[:,1]]; @printf(\"| %1.5f |\\n\",h₂)\n",
    "@printf(\"h₃    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_infty[:,2]]; @printf(\"| %1.5f |\\n\",h₃)\n",
    "@printf(\"h₄    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_infty[:,3]]; @printf(\"| %1.5f |\\n\",h₄)\n",
    "@printf(\"h₅    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_infty[:,4]]; @printf(\"| %1.5f |\\n\",h₅)\n",
    "print(\"=====================================================================\\n\")\n",
    "@printf(\"Estimation Result: \\n\")\n",
    "print(\"==============================================================\\n\")\n",
    "@printf(\"Data \\\\ N  ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"\\n\")\n",
    "print(\"--------------------------------------------------------------\\n\")\n",
    "@printf(\"Up to t=2 ||\"); [@printf(\" %1.5f |\", i) for i in result_infty[:,1,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_infty[:,1,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=3 ||\"); [@printf(\" %1.5f |\", i) for i in result_infty[:,2,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_infty[:,2,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=4 ||\"); [@printf(\" %1.5f |\", i) for i in result_infty[:,3,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_infty[:,3,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=5 ||\"); [@printf(\" %1.5f |\", i) for i in result_infty[:,4,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_infty[:,4,2]]; @printf(\"\\n\")\n",
    "print(\"==============================================================\\n\")\n",
    "@printf(\"Standard errors in parentheses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $N$ grows, we see that our empirical hazard rates approach to our theory as they should. The table for estimation results show that i) holding constant the available information across time, the MLE estimates tend to the true value as the number of observations increase and ii) holding the number of observations constant, using more information on the agents choices across time helps efficiency. It is also interesting to see that using information up to $t=3$ does not have any improvement on the estimates compared to using information up to $t=2$. This is because no one quits at $t=3$; thus, there is no information to use for our estimation there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Sanity check for simulation for the infinite horizon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37.463248 seconds (234.16 k allocations: 13.107 MiB, 0.24% compilation time)\n"
     ]
    }
   ],
   "source": [
    "γ=2.3;δ=2.0;w=0.65;β=0.96;T=100;\n",
    "N=5000;iter=50000;Tdata=5;\n",
    "v₀, v₁, V, d, _ = VFI(γ,δ,w,β,T,print_flag=0);\n",
    "h₁, h₂, h₃, h₄, h₅ = hazard(d, γ, δ)\n",
    "h_rate_simul=SharedArray{Float64}(zeros(iter,4))\n",
    "Random.seed!(42)\n",
    "@time @sync @distributed for n = 1:iter\n",
    "    γData, δData, dData, xData, ξ = simul_data_infty(N,T,γ,δ,d,Tdata);\n",
    "    h_rate_simul[n,1] = sum((dData[:,1].==1).&(dData[:,2].==0))/sum((dData[:,1].==1))\n",
    "    h_rate_simul[n,2] = sum((dData[:,2].==1).&(dData[:,3].==0))/sum((dData[:,2].==1))\n",
    "    h_rate_simul[n,3] = sum((dData[:,3].==1).&(dData[:,4].==0))/sum((dData[:,3].==1))\n",
    "    h_rate_simul[n,4] = sum((dData[:,4].==1).&(dData[:,5].==0))/sum((dData[:,4].==1))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Validating the Simulation of 5000 Observations with 50000 Iterations ---\n",
      "h2: 0.465116, h2_data: 0.465035 \n",
      "h3: 0.000000, h3_data: 0.000000 \n",
      "h4: 0.179695, h4_data: 0.179722 \n",
      "h5: 0.198052, h5_data: 0.198077 \n"
     ]
    }
   ],
   "source": [
    "# Checking whether the simulation is sensible\n",
    "print(\"--- Validating the Simulation of $N Observations with $iter Iterations ---\\n\")\n",
    "@printf(\"h2: %3.6f, h2_data: %3.6f \\n\",h₂,mean(h_rate_simul[:,1]))\n",
    "@printf(\"h3: %3.6f, h3_data: %3.6f \\n\",h₃,mean(h_rate_simul[:,2]))\n",
    "@printf(\"h4: %3.6f, h4_data: %3.6f \\n\",h₄,mean(h_rate_simul[:,3]))\n",
    "@printf(\"h5: %3.6f, h5_data: %3.6f \\n\",h₅,mean(h_rate_simul[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative solution to the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 10:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 16:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 4:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 11:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 12:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 14:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 6:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 7:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 15:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 13:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 5:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 9:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 8:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 3:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n",
      "      From worker 2:\t\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `c:\\Users\\jaepil\\Documents\\GitHub\\Prof_Miller_structural_econometrics\\Project.toml`\n"
     ]
    }
   ],
   "source": [
    "# Importing packages...\n",
    "using Pkg; Pkg.activate(\"./..\")\n",
    "using Distributions, Statistics, Random,\n",
    "    LinearAlgebra, Distances, SharedArrays, \n",
    "    Optim, ForwardDiff, NLSolversBase, \n",
    "    Plots, Printf, LaTeXStrings, PlotThemes;\n",
    "#=\n",
    "Distributed.jl is used for parallelization\n",
    "@everywhere is a macro to tell all the processors do the commands that follows\n",
    "@distributed is a macro to tell all the processors share the work on the loop\n",
    "SharedArrays{T} type is a type of Arrays that multiple processors can have access\n",
    "@sync is a macro to tell the processors do the loop in a synchronized manner\n",
    "=#\n",
    "using Distributed; addprocs(15); # Use addprocs(N-1) to use all N processors in your PC.\n",
    "@everywhere begin\n",
    "    using Pkg; Pkg.activate(\"./..\")\n",
    "    using Distributions, Statistics, Random,\n",
    "        LinearAlgebra, Distances, SharedArrays, \n",
    "        Optim, ForwardDiff, NLSolversBase, \n",
    "        Plots, Printf, LaTeXStrings, PlotThemes;\n",
    "end;\n",
    "\n",
    "@everywhere function u(j,γ,δ,w)\n",
    "    # Per-period utility function\n",
    "    return j * γ/(γ+δ) + (1-j) * w\n",
    "end\n",
    "\n",
    "@everywhere function Val_5(γ,δ,w,t,β)\n",
    "    # The value function for the two-period model\n",
    "    # findmin(itr)[1] returns maximum value\n",
    "    if t==5\n",
    "        return findmax([u(j,γ,δ,w) for j=0:1])[1]\n",
    "    else\n",
    "        return findmax([u(j,γ,δ,w) + β*(j*(γ/(γ+δ) * Val_5(γ+1,δ,w,t+1,β) + δ/(γ+δ) * Val_5(γ,δ+1,w,t+1,β))+\n",
    "                                        (1-j)*Val_5(γ,δ,w,t+1,β)) for j=0:1])[1]\n",
    "    end\n",
    "end\n",
    "\n",
    "@everywhere function d_dyn_5(γ,δ,w,t,β)\n",
    "    # The policy function for the two-period model\n",
    "    # findmin(itr)[2] is argmax. \"-1\" is there to match the index in Julia (1,2) to our choice index (0,1)\n",
    "    if t==5\n",
    "        return findmax([u(j,γ,δ,w) for j=0:1])[2]-1 \n",
    "    else\n",
    "        return findmax([u(j,γ,δ,w) + β*(j*(γ/(γ+δ) * Val_5(γ+1,δ,w,t+1,β) + δ/(γ+δ) * Val_5(γ,δ+1,w,t+1,β))+\n",
    "                                        (1-j)*Val_5(γ,δ,w,t+1,β)) for j=0:1])[2]-1\n",
    "    end\n",
    "end\n",
    "\n",
    "@everywhere function simul_data(N,T,γ,δ,w,β)\n",
    "    γData = Array{Float64}(zeros(N,T));\n",
    "    δData = Array{Float64}(zeros(N,T));\n",
    "    dData = Array{Float64}(zeros(N,T));\n",
    "    xData = Array{Float64}(zeros(N,T));\n",
    "    \n",
    "    #=\n",
    "    Again, everyone has different ξ, but each person retains ξ over time (i.e., no learning by doing).\n",
    "    We only get to know 'how good we are' as we invent and observe outcomes.\n",
    "    =#\n",
    "    γData[:,1] .= γ;\n",
    "    δData[:,1] .= δ;\n",
    "    ξ = rand(Beta(γ,δ),N);\n",
    "\n",
    "    #=\n",
    "    broadcast() applies the function d_dyn_5 that takes 4 scalar arguments and\n",
    "    applies it element-wise over the vectors γData[:,1] and δData[:,1]\n",
    "    while fixing w,1,β as scalars.\n",
    "    =#\n",
    "    dData[:,1] = broadcast(d_dyn_5,γData[:,1],δData[:,1],w,1,β);\n",
    "    xData[:,1] = rand.(Bernoulli.(ξ)) .* dData[:,1];\n",
    "    for t=2:T\n",
    "        γData[:,t] .= γData[:,t-1] + dData[:,t-1] .* (1 .* xData[:,t-1])\n",
    "        δData[:,t] .= δData[:,t-1] + dData[:,t-1] .* (1 .* (1 .- xData[:,t-1]))\n",
    "        dData[:,t] .= broadcast(d_dyn_5,γData[:,t],δData[:,t],w,t,β)\n",
    "        xData[:,t] .= rand.(Bernoulli.(ξ)) .* dData[:,t];\n",
    "    end\n",
    "    return γData, δData, dData, xData, ξ\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function hazard_5(γ, δ, w, β)\n",
    "\n",
    "    d = Array{Int64}(zeros(5,5)) # number of successes-1, time\n",
    "    for t = 1:5\n",
    "        for i = 1:t\n",
    "            d[i,t] = d_dyn_5(γ+(i-1),δ+(t-i),w,t,β)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    h₁ = 1-d[1,1]\n",
    "    h₂ = 1/(1-h₁) * (\n",
    "        d[1,1] * γ/(γ+δ) * (1-d[2,2]) +\n",
    "        d[1,1] * δ/(γ+δ) * (1-d[1,2])\n",
    "        ) \n",
    "    h₃ = 1/(1-h₁) * 1/(1-h₂) * (\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * (1-d[3,3])    +\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * (1-d[2,3])    + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * (1-d[2,3])    +\n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * (1-d[1,3])\n",
    "        ) \n",
    "    h₄ = 1/(1-h₁) * 1/(1-h₂) * 1/(1-h₃) * (\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (γ+2)/(γ+δ+2) * (1-d[4,4]) +\n",
    "            \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (δ  )/(γ+δ+2) * (1-d[3,4]) +\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * (1-d[3,4]) +\n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * (1-d[3,4]) +\n",
    "    \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * (1-d[2,4]) +\n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * (1-d[2,4]) +\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * (1-d[2,4]) +\n",
    "    \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * (1-d[1,4])\n",
    "        )\n",
    "    h₅ = 1/(1-h₂) * 1/(1-h₃) * 1/(1-h₄)*(\n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (γ+2)/(γ+δ+2) * d[4,4] * (γ+3)/(γ+δ+3) * (1-d[5,5]) +\n",
    "            \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (γ+2)/(γ+δ+2) * d[4,4] * (δ  )/(γ+δ+3) * (1-d[4,5]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (δ  )/(γ+δ+2) * d[3,4] * (γ+2)/(γ+δ+3) * (1-d[4,5]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * d[3,4] * (γ+2)/(γ+δ+3) * (1-d[4,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * d[3,4] * (γ+2)/(γ+δ+3) * (1-d[4,5]) +\n",
    "    \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (γ+1)/(γ+δ+1) * d[3,3] * (δ  )/(γ+δ+2) * d[3,4] * (δ+1)/(γ+δ+3) * (1-d[3,5]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * d[3,4] * (δ+1)/(γ+δ+3) * (1-d[3,5]) + \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * d[2,4] * (γ+1)/(γ+δ+3) * (1-d[3,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * d[2,4] * (γ+1)/(γ+δ+3) * (1-d[3,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * d[2,4] * (γ+1)/(γ+δ+3) * (1-d[3,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (γ+1)/(γ+δ+2) * d[3,4] * (δ+1)/(γ+δ+3) * (1-d[3,5]) +\n",
    "    \n",
    "        d[1,1] * γ/(γ+δ) * d[2,2] * (δ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * d[2,4] * (δ+2)/(γ+δ+3) * (1-d[2,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (γ  )/(γ+δ+1) * d[2,3] * (δ+1)/(γ+δ+2) * d[2,4] * (δ+2)/(γ+δ+3) * (1-d[2,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (γ  )/(γ+δ+2) * d[2,4] * (δ+2)/(γ+δ+3) * (1-d[2,5]) + \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * d[1,4] * (γ  )/(γ+δ+3) * (1-d[2,5]) +\n",
    "        \n",
    "        d[1,1] * δ/(γ+δ) * d[1,2] * (δ+1)/(γ+δ+1) * d[1,3] * (δ+2)/(γ+δ+2) * d[1,4] * (δ+3)/(γ+δ+3) * (1-d[1,5])\n",
    "    )\n",
    "      return h₁, h₂, h₃, h₄, h₅\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere function logLikelihood_5(log_γ,δ,w,β,qData,time)\n",
    "    γ = exp(log_γ[1])\n",
    "    h₁, h₂, h₃, h₄, h₅ = hazard_5(γ, δ, w, β)\n",
    "    if time ==2 \n",
    "          return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                           (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                           (qData.==2).*(1-h₁).*(1-h₂)))\n",
    "    elseif time ==3\n",
    "          return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                           (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                           (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+ \n",
    "                           (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃)))\n",
    "    elseif time ==4\n",
    "          return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                           (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                           (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+\n",
    "                           (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃).*(  h₄) .+\n",
    "                           (qData.==4).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄))) \n",
    "    else # time ==5 \n",
    "          return -sum(log.((qData.==0).*(  h₁) .+ \n",
    "                           (qData.==1).*(1-h₁).*(  h₂) .+ \n",
    "                           (qData.==2).*(1-h₁).*(1-h₂).*(  h₃) .+\n",
    "                           (qData.==3).*(1-h₁).*(1-h₂).*(1-h₃).*(  h₄) .+\n",
    "                           (qData.==4).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄).*(  h₅) .+\n",
    "                           (qData.==5).*(1-h₁).*(1-h₂).*(1-h₃).*(1-h₄).*(1-h₅)))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.46511627906976744, 0.0, 0.1796945193171608, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "γ=2.3;δ=2.0;w=0.5;β=0.96\n",
    "N_vec = [500,5_000,50_000,500_000];Tdata=5;\n",
    "_, _, dData, _, _ = simul_data(N_vec[end],Tdata,γ,δ,w,β);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=    500 using information up to t=2 is done! \n",
      "N=    500 using information up to t=3 is done! \n",
      "N=    500 using information up to t=4 is done! \n",
      "N=    500 using information up to t=5 is done! \n",
      "N=   5000 using information up to t=2 is done! \n",
      "N=   5000 using information up to t=3 is done! \n",
      "N=   5000 using information up to t=4 is done! \n",
      "N=   5000 using information up to t=5 is done! \n",
      "N=  50000 using information up to t=2 is done! \n",
      "N=  50000 using information up to t=3 is done! \n",
      "N=  50000 using information up to t=4 is done! \n",
      "N=  50000 using information up to t=5 is done! \n",
      "N= 500000 using information up to t=2 is done! \n",
      "N= 500000 using information up to t=3 is done! \n",
      "N= 500000 using information up to t=4 is done! \n",
      "N= 500000 using information up to t=5 is done! \n"
     ]
    }
   ],
   "source": [
    "h₁, h₂, h₃, h₄, h₅ = hazard_5(γ, δ, w, β)\n",
    "#=\n",
    "lb must be set so that everyone decides to invent in the first period\n",
    "ub must be set so that the -sum(log.(INSIDE)) does not have any zeros in INSIDE in log-likelihood\n",
    "=#\n",
    "lb = log(1.50)\n",
    "ub = log(3.5)\n",
    "Random.seed!(42)\n",
    "deviation=randn()\n",
    "γ_init = [min(max(log(γ+deviation/4),lb),ub-0.005)]\n",
    "h_rate_5 = Array{Float64}(zeros(length(N_vec),Tdata-1));\n",
    "result_5 = Array{Float64}(zeros(length(N_vec),Tdata-1,2));\n",
    "for i = 1:length(N_vec)\n",
    "    N = N_vec[i]\n",
    "    h_rate_5[i,1] = sum((dData[1:N,1].==1).&(dData[1:N,2].==0))/sum((dData[1:N,1].==1))\n",
    "    h_rate_5[i,2] = sum((dData[1:N,2].==1).&(dData[1:N,3].==0))/sum((dData[1:N,2].==1))\n",
    "    h_rate_5[i,3] = sum((dData[1:N,3].==1).&(dData[1:N,4].==0))/sum((dData[1:N,3].==1))\n",
    "    h_rate_5[i,4] = sum((dData[1:N,4].==1).&(dData[1:N,5].==0))/sum((dData[1:N,4].==1))\n",
    "    for t = 2:Tdata\n",
    "        qData = sum(dData[1:N,1:t],dims=2);\n",
    "        func(γ) = logLikelihood_5(γ[1],δ,w,β,qData,t)\n",
    "        opt = optimize(func, lb, ub)\n",
    "        γ_hat_optim = exp(opt.minimizer)\n",
    "        σ_hat_optim = sqrt(inv(ForwardDiff.derivative(x -> ForwardDiff.derivative(func,x),opt.minimizer)))\n",
    "        @printf(\"N=%7i using information up to t=%1i is done! \\n\",N,t)\n",
    "        result_5[i,t-1,1] = γ_hat_optim\n",
    "        result_5[i,t-1,2] = σ_hat_optim\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Estimating γ in an Infinite Horizon Model -------------\n",
      "Parameters: γ=2.3, δ=2.0, w=0.5, β=0.96 \n",
      "Initial Point: 2.1610, Lower bound  : 1.5000, Upper bound: 3.5000 \n",
      "Hazard Rate: Data vs Theory \n",
      "===========================================================\n",
      "N     ||     500 |    5000 |   50000 |  500000 ||  Theory |\n",
      "-----------------------------------------------------------\n",
      "h₂    || 0.47400 | 0.46980 | 0.46452 | 0.46492 || 0.46512 |\n",
      "h₃    || 0.00000 | 0.00000 | 0.00000 | 0.00000 || 0.00000 |\n",
      "h₄    || 0.21673 | 0.17729 | 0.17995 | 0.18000 || 0.17969 |\n",
      "h₅    || 0.00000 | 0.00000 | 0.00000 | 0.00000 || 0.00000 |\n",
      "===========================================================\n",
      "Estimation Result: \n",
      "====================================================\n",
      "Data \\ N  ||     500 |    5000 |   50000 |  500000 |\n",
      "----------------------------------------------------\n",
      "Up to t=2 || 2.21941 | 2.25713 | 2.30552 | 2.30183 |\n",
      "          ||(0.08956)|(0.02834)|(0.00897)|(0.00284)|\n",
      "Up to t=3 || 2.21941 | 2.25713 | 2.30552 | 2.30183 |\n",
      "          ||(0.08956)|(0.02834)|(0.00897)|(0.00284)|\n",
      "Up to t=4 || 2.11318 | 2.27556 | 2.30329 | 2.30027 |\n",
      "          ||(0.07819)|(0.02492)|(0.00786)|(0.00249)|\n",
      "Up to t=5 || 2.11318 | 2.27556 | 2.30329 | 2.30027 |\n",
      "          ||(0.07819)|(0.02492)|(0.00786)|(0.00249)|\n",
      "====================================================\n",
      "Standard errors in parentheses."
     ]
    }
   ],
   "source": [
    "# Print MLE estimation results\n",
    "print(\"------------ Estimating γ in an Infinite Horizon Model -------------\\n\")\n",
    "print(\"Parameters: γ=$γ, δ=$δ, w=$w, β=$β \\n\")\n",
    "@printf(\"Initial Point: %1.4f, Lower bound  : %1.4f, Upper bound: %1.4f \\n\", exp(γ_init[1]), exp(lb), exp(ub))\n",
    "@printf(\"Hazard Rate: Data vs Theory \\n\")\n",
    "print(\"===========================================================\\n\")\n",
    "@printf(\"N     ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"|  Theory |\\n\") \n",
    "print(\"-----------------------------------------------------------\\n\")\n",
    "@printf(\"h₂    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_5[:,1]]; @printf(\"| %1.5f |\\n\",h₂)\n",
    "@printf(\"h₃    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_5[:,2]]; @printf(\"| %1.5f |\\n\",h₃)\n",
    "@printf(\"h₄    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_5[:,3]]; @printf(\"| %1.5f |\\n\",h₄)\n",
    "@printf(\"h₅    ||\"); [@printf(\" %1.5f |\", i) for i in h_rate_5[:,4]]; @printf(\"| %1.5f |\\n\",h₅)\n",
    "print(\"===========================================================\\n\")\n",
    "@printf(\"Estimation Result: \\n\")\n",
    "print(\"====================================================\\n\")\n",
    "@printf(\"Data \\\\ N  ||\"); [@printf(\" %7i |\", i) for i in N_vec]; @printf(\"\\n\")\n",
    "print(\"----------------------------------------------------\\n\")\n",
    "@printf(\"Up to t=2 ||\"); [@printf(\" %1.5f |\", i) for i in result_5[:,1,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_5[:,1,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=3 ||\"); [@printf(\" %1.5f |\", i) for i in result_5[:,2,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_5[:,2,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=4 ||\"); [@printf(\" %1.5f |\", i) for i in result_5[:,3,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_5[:,3,2]]; @printf(\"\\n\")\n",
    "@printf(\"Up to t=5 ||\"); [@printf(\" %1.5f |\", i) for i in result_5[:,4,1]]; @printf(\"\\n\")\n",
    "@printf(\"          ||\"); [@printf(\"(%1.5f)|\", i) for i in result_5[:,4,2]]; @printf(\"\\n\")\n",
    "print(\"====================================================\\n\")\n",
    "@printf(\"Standard errors in parentheses.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c18e99b726c8fd8138ce28f5a9b53e15561b8db98b4e4eb42b1a944dd068f28"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
